{"cells":[{"cell_type":"markdown","metadata":{"id":"XaS3hn4xtb2v"},"source":["# **미니프로젝트 4차 1대1 문의 내용 유형 분류기**\n","# 단계3 : Text classification\n","\n","### 문제 정의\n","> 1:1 문의 내용 분류 문제<br>\n","> 1. 문의 내용 분석\n","> 2. 문의 내용 분류 모델 성능 평가\n","### 학습 데이터\n","> * 1:1 문의 내용 데이터 : train.csv\n","\n","### 변수 소개\n","> * text : 문의 내용\n","> * label : 문의 유형\n","\n","### References\n","> * Machine Learning\n",">> * [sklearn-tutorial](https://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html)\n","> * Deep Learning\n",">> * [Google Tutorial](https://developers.google.com/machine-learning/guides/text-classification)\n",">> * [Tensorflow Tutorial](https://www.tensorflow.org/tutorials/keras/text_classification)\n",">> * [Keras-tutorial](https://keras.io/examples/nlp/text_classification_from_scratch/)\n",">> * [BERT-tutorial](https://www.tensorflow.org/text/guide/bert_preprocessing_guide)"]},{"cell_type":"markdown","metadata":{"id":"FlRWJB2w6Ip6"},"source":["## 1. 개발 환경 설정"]},{"cell_type":"markdown","metadata":{"id":"d5KWp7Zetb2x"},"source":["### 1-1. 라이브러리 설치"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L7YgIAZXtb2x","executionInfo":{"status":"ok","timestamp":1680843280503,"user_tz":-540,"elapsed":10461,"user":{"displayName":"라크샤사","userId":"01838305003834813418"}},"outputId":"dd8f488e-8214-4bce-82de-1a2a9b6807bf"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting konlpy\n","  Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.4/19.4 MB\u001b[0m \u001b[31m72.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (1.4.4)\n","Requirement already satisfied: seaborn in /usr/local/lib/python3.9/dist-packages (0.12.2)\n","Requirement already satisfied: gensim in /usr/local/lib/python3.9/dist-packages (4.3.1)\n","Requirement already satisfied: wordcloud in /usr/local/lib/python3.9/dist-packages (1.8.2.2)\n","Collecting python-mecab-ko\n","  Downloading python_mecab_ko-1.3.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (575 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m575.6/575.6 KB\u001b[0m \u001b[31m50.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting wget\n","  Downloading wget-3.2.zip (10 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.9/dist-packages (from konlpy) (4.9.2)\n","Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.9/dist-packages (from konlpy) (1.22.4)\n","Collecting JPype1>=0.7.0\n","  Downloading JPype1-1.4.1-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (465 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m465.3/465.3 KB\u001b[0m \u001b[31m36.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas) (2022.7.1)\n","Requirement already satisfied: matplotlib!=3.6.1,>=3.1 in /usr/local/lib/python3.9/dist-packages (from seaborn) (3.7.1)\n","Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.9/dist-packages (from gensim) (6.3.0)\n","Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.9/dist-packages (from gensim) (1.10.1)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.9/dist-packages (from wordcloud) (8.4.0)\n","Collecting python-mecab-ko-dic\n","  Downloading python_mecab_ko_dic-2.1.1.post2-py3-none-any.whl (34.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.5/34.5 MB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from JPype1>=0.7.0->konlpy) (23.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (0.11.0)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (4.39.3)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.0.7)\n","Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (5.12.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.4.4)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (3.0.9)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n","Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib-resources>=3.2.0->matplotlib!=3.6.1,>=3.1->seaborn) (3.15.0)\n","Building wheels for collected packages: wget\n","  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9676 sha256=3a76638c6a75ed6a00bc36344b743fe86ffcfee7117797c830f1866c95fd8c61\n","  Stored in directory: /root/.cache/pip/wheels/04/5f/3e/46cc37c5d698415694d83f607f833f83f0149e49b3af9d0f38\n","Successfully built wget\n","Installing collected packages: wget, python-mecab-ko-dic, python-mecab-ko, JPype1, konlpy\n","Successfully installed JPype1-1.4.1 konlpy-0.6.0 python-mecab-ko-1.3.3 python-mecab-ko-dic-2.1.1.post2 wget-3.2\n"]}],"source":["# 필요 라이브러리부터 설치할께요.\n","!pip install konlpy pandas seaborn gensim wordcloud python-mecab-ko wget"]},{"cell_type":"markdown","metadata":{"id":"pI12y3zMtb2y"},"source":["### 1-2. 라이브러리 import"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"NgWxwIGFtb2y","executionInfo":{"status":"ok","timestamp":1680843285062,"user_tz":-540,"elapsed":4563,"user":{"displayName":"라크샤사","userId":"01838305003834813418"}}},"outputs":[],"source":["from mecab import MeCab\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import wget,os\n","from IPython.display import display\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import matplotlib.font_manager as fm\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","import nltk\n","import wget,os"]},{"cell_type":"markdown","metadata":{"id":"o0cra3K4tb2y"},"source":["### 1-3. 한글 글꼴 설정(Windows)"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"4DVPacHAtb2z","executionInfo":{"status":"ok","timestamp":1680830735472,"user_tz":-540,"elapsed":19,"user":{"displayName":"라크샤사","userId":"01838305003834813418"}}},"outputs":[],"source":["# if not os.path.exists(\"malgun.ttf\"): \n","#     wget.download(\"https://www.wfonts.com/download/data/2016/06/13/malgun-gothic/malgun.ttf\")\n","# if 'malgun' not in fm.fontManager.findfont(\"Malgun Gothic\"):\n","#     fm.fontManager.addfont(\"malgun.ttf\")\n","# if plt.rcParams['font.family']!= [\"Malgun Gothic\"]:\n","#     plt.rcParams['font.family']= [font for font in fm.fontManager.ttflist if 'malgun.ttf' in font.fname][-1].name\n","# plt.rcParams['axes.unicode_minus'] = False #한글 폰트 사용시 마이너스 폰트 깨짐 해결\n","# assert plt.rcParams['font.family'] == [\"Malgun Gothic\"], \"한글 폰트가 설정되지 않았습니다.\"\n","# FONT_PATH = \"malgun.ttf\""]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4x0c7f6Atb2z","executionInfo":{"status":"ok","timestamp":1680843289288,"user_tz":-540,"elapsed":4236,"user":{"displayName":"라크샤사","userId":"01838305003834813418"}},"outputId":"ee4156ee-45d1-44ce-cc2e-2d9da8fed0cb"},"outputs":[{"output_type":"stream","name":"stdout","text":["Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","The following NEW packages will be installed:\n","  fonts-nanum\n","0 upgraded, 1 newly installed, 0 to remove and 24 not upgraded.\n","Need to get 9,599 kB of archives.\n","After this operation, 29.6 MB of additional disk space will be used.\n","Get:1 http://archive.ubuntu.com/ubuntu focal/universe amd64 fonts-nanum all 20180306-3 [9,599 kB]\n","Fetched 9,599 kB in 0s (56.3 MB/s)\n","debconf: unable to initialize frontend: Dialog\n","debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 1.)\n","debconf: falling back to frontend: Readline\n","debconf: unable to initialize frontend: Readline\n","debconf: (This frontend requires a controlling tty.)\n","debconf: falling back to frontend: Teletype\n","dpkg-preconfigure: unable to re-open stdin: \n","Selecting previously unselected package fonts-nanum.\n","(Reading database ... 122349 files and directories currently installed.)\n","Preparing to unpack .../fonts-nanum_20180306-3_all.deb ...\n","Unpacking fonts-nanum (20180306-3) ...\n","Setting up fonts-nanum (20180306-3) ...\n","Processing triggers for fontconfig (2.13.1-2ubuntu3) ...\n"]}],"source":["!sudo apt-get install -y fonts-nanum"]},{"cell_type":"markdown","metadata":{"id":"bEiYgeVStb2z"},"source":["### 1-4. 자바 경로 설정(Windows)"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"JA3F-28mtb2z","executionInfo":{"status":"ok","timestamp":1680830743763,"user_tz":-540,"elapsed":22,"user":{"displayName":"라크샤사","userId":"01838305003834813418"}}},"outputs":[],"source":["# os.environ['JAVA_HOME'] = \"C:\\Program Files\\Java\\jdk-19\""]},{"cell_type":"markdown","metadata":{"id":"AoJRTddjtb2z"},"source":["### 1-3. 한글 글꼴 설정(Colab)"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_krnnvlKtb2z","executionInfo":{"status":"ok","timestamp":1680843290545,"user_tz":-540,"elapsed":1260,"user":{"displayName":"라크샤사","userId":"01838305003834813418"}},"outputId":"8798cc57-560f-4eb1-f0b5-eb70b1201eec"},"outputs":[{"output_type":"stream","name":"stdout","text":["Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","fonts-nanum is already the newest version (20180306-3).\n","0 upgraded, 0 newly installed, 0 to remove and 24 not upgraded.\n"]}],"source":["!sudo apt-get install -y fonts-nanum"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oSgyKaSHtb20","executionInfo":{"status":"ok","timestamp":1680843290546,"user_tz":-540,"elapsed":11,"user":{"displayName":"라크샤사","userId":"01838305003834813418"}},"outputId":"0c8e8086-d068-4fa6-8017-360bcb39d172"},"outputs":[{"output_type":"stream","name":"stdout","text":["NanumGothic\n"]}],"source":["FONT_PATH = '/usr/share/fonts/truetype/nanum/NanumGothic.ttf'\n","font_name = fm.FontProperties(fname=FONT_PATH, size=10).get_name()\n","fm.fontManager.addfont(FONT_PATH)\n","print(font_name)\n","\n","plt.rcParams['font.family']=[font_name]\n","plt.rcParams['axes.unicode_minus']=False\n","assert plt.rcParams['font.family'] == [font_name], \"한글 폰트가 설정되지 않았습니다.\""]},{"cell_type":"markdown","metadata":{"id":"47XjblL5tb20"},"source":["### 1-4. 구글드라이브 연결(Colab)"]},{"cell_type":"code","execution_count":38,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Uk9fABQltb20","executionInfo":{"status":"ok","timestamp":1680849063718,"user_tz":-540,"elapsed":3545,"user":{"displayName":"라크샤사","userId":"01838305003834813418"}},"outputId":"c578fb8c-0acc-4b2a-f868-4ba8d0047f56"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"hlwIciiOtb20"},"source":["## 2. 전처리한 데이터 불러오기\n","* 1, 2일차에 전처리한 데이터를 불러옵니다.\n","* sparse data에 대해서는 scipy.sparse.load_npz 활용"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"4SbsGlvjtb20","executionInfo":{"status":"ok","timestamp":1680843340885,"user_tz":-540,"elapsed":4727,"user":{"displayName":"라크샤사","userId":"01838305003834813418"}}},"outputs":[],"source":["import scipy.sparse\n","import numpy as np\n","\n","# sparse matrix 불러오기\n","X_tfidf_train = scipy.sparse.load_npz('/content/drive/MyDrive/aivle/4차 미니프로젝트/X_tfidf_train.npz')\n","X_tfidf_val = scipy.sparse.load_npz('/content/drive/MyDrive/aivle/4차 미니프로젝트/X_tfidf_val.npz')\n","X_tfidf_te = scipy.sparse.load_npz('/content/drive/MyDrive/aivle/4차 미니프로젝트/X_tfidf_te.npz')\n","\n","# numpy array 불러오기\n","X_mor_sequence_train = np.load('/content/drive/MyDrive/aivle/4차 미니프로젝트/X_mor_sequence_train.npy')\n","X_mor_sequence_val = np.load('/content/drive/MyDrive/aivle/4차 미니프로젝트/X_mor_sequence_val.npy')\n","X_mor_sequence_te = np.load('/content/drive/MyDrive/aivle/4차 미니프로젝트/X_mor_sequence_te.npy')\n","\n","# y 불러오기\n","y_train = np.load('/content/drive/MyDrive/aivle/4차 미니프로젝트/y_train.npy')\n","y_val = np.load('/content/drive/MyDrive/aivle/4차 미니프로젝트/y_val.npy')"]},{"cell_type":"code","source":["x_test = scipy.sparse.load_npz('/content/drive/MyDrive/aivle/4차 미니프로젝트/x_test.npz')"],"metadata":{"id":"KbK9GBQSbwSz","executionInfo":{"status":"ok","timestamp":1680843341567,"user_tz":-540,"elapsed":699,"user":{"displayName":"라크샤사","userId":"01838305003834813418"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["x_test_sp_tfidf = scipy.sparse.load_npz('/content/drive/MyDrive/aivle/4차 미니프로젝트/x_test_sp_tfidf.npz')"],"metadata":{"id":"KImLBkosb9JX","executionInfo":{"status":"ok","timestamp":1680849345070,"user_tz":-540,"elapsed":860,"user":{"displayName":"라크샤사","userId":"01838305003834813418"}}},"execution_count":43,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PzadswDUtb21"},"source":["## 3. Machine Learning(N-grams)\n","* N-gram으로 전처리한 데이터를 이용하여 3개 이상의 Machine Learning 모델 학습 및 성능 분석\n","> * [sklearn-tutorial](https://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html)"]},{"cell_type":"markdown","metadata":{"id":"fEPcz4iGtb21"},"source":["### 3-1. Model 1"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"YJzN22YPtb21","executionInfo":{"status":"ok","timestamp":1680843344072,"user_tz":-540,"elapsed":788,"user":{"displayName":"라크샤사","userId":"01838305003834813418"}}},"outputs":[],"source":["from sklearn.linear_model import LogisticRegression\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import f1_score, confusion_matrix, classification_report"]},{"cell_type":"code","source":["X_tfidf_train.shape, x_test.shape, y_train.shape, X_tfidf_val.shape, y_val.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NqQJBBTZo3is","executionInfo":{"status":"ok","timestamp":1680843344740,"user_tz":-540,"elapsed":4,"user":{"displayName":"라크샤사","userId":"01838305003834813418"}},"outputId":"82e26136-99d7-456e-a223-ba7244e55e64"},"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((2084, 8568), (929, 8568), (2084,), (927, 8568), (927,))"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["prob = model_linear.predict_proba(x_test)\n","prob = pd.DataFrame(prob)"],"metadata":{"id":"w1CztIycD4Ti","executionInfo":{"status":"ok","timestamp":1680843758385,"user_tz":-540,"elapsed":546,"user":{"displayName":"라크샤사","userId":"01838305003834813418"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["prob[:5]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"EzqD0vYcEsRI","executionInfo":{"status":"ok","timestamp":1680843760222,"user_tz":-540,"elapsed":20,"user":{"displayName":"라크샤사","userId":"01838305003834813418"}},"outputId":"78182df9-941e-46ce-fb0c-13cad18a5562"},"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["          0         1         2         3         4\n","0  0.070780  0.142532  0.073517  0.707200  0.005971\n","1  0.228574  0.140533  0.223782  0.397791  0.009319\n","2  0.966506  0.017278  0.006340  0.006346  0.003530\n","3  0.962792  0.007515  0.023959  0.004239  0.001496\n","4  0.630193  0.237220  0.081147  0.029603  0.021838"],"text/html":["\n","  <div id=\"df-d0d7b0a1-f148-4e47-ac61-8f2da17b4892\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.070780</td>\n","      <td>0.142532</td>\n","      <td>0.073517</td>\n","      <td>0.707200</td>\n","      <td>0.005971</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.228574</td>\n","      <td>0.140533</td>\n","      <td>0.223782</td>\n","      <td>0.397791</td>\n","      <td>0.009319</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.966506</td>\n","      <td>0.017278</td>\n","      <td>0.006340</td>\n","      <td>0.006346</td>\n","      <td>0.003530</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.962792</td>\n","      <td>0.007515</td>\n","      <td>0.023959</td>\n","      <td>0.004239</td>\n","      <td>0.001496</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.630193</td>\n","      <td>0.237220</td>\n","      <td>0.081147</td>\n","      <td>0.029603</td>\n","      <td>0.021838</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d0d7b0a1-f148-4e47-ac61-8f2da17b4892')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-d0d7b0a1-f148-4e47-ac61-8f2da17b4892 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-d0d7b0a1-f148-4e47-ac61-8f2da17b4892');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":19}]},{"cell_type":"code","source":["prob.to_csv('logistic_prob.csv', index = False)"],"metadata":{"id":"W4vE3Oq7G2Fi","executionInfo":{"status":"ok","timestamp":1680843974992,"user_tz":-540,"elapsed":672,"user":{"displayName":"라크샤사","userId":"01838305003834813418"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["model_linear = LogisticRegression(C = 5, max_iter = 1000, penalty = 'l2', solver =  'liblinear')\n","model_linear.fit(X_tfidf_train, y_train)\n","y_pred = model_linear.predict(x_test_sp_tfidf)"],"metadata":{"id":"vKXFhKgZGToX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_linear = LogisticRegression(C = 5, max_iter = 1000, penalty = 'l2', solver =  'liblinear')\n","model_linear.fit(X_tfidf_train, y_train)\n","y_pred = model_linear.predict(x_test_sp_tfidf)\n","print(classification_report(y_pred, y_val))\n","print(f1_score(y_pred, y_val, average='macro'))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":396},"id":"wD7sm13SxcyN","executionInfo":{"status":"error","timestamp":1680849422230,"user_tz":-540,"elapsed":577,"user":{"displayName":"라크샤사","userId":"01838305003834813418"}},"outputId":"96ad5230-4792-4b78-fb92-6ce8e20d1377"},"execution_count":44,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-44-3d5e96c4e497>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel_linear\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_tfidf_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_linear\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test_sp_tfidf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'macro'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mclassification_report\u001b[0;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[1;32m   2308\u001b[0m     \"\"\"\n\u001b[1;32m   2309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2310\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2312\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \"\"\"\n\u001b[0;32m---> 86\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y_true\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y_pred\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    395\u001b[0m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 397\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    398\u001b[0m             \u001b[0;34m\"Found input variables with inconsistent numbers of samples: %r\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m             \u001b[0;34m%\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [929, 927]"]}]},{"cell_type":"code","source":["y_pred_df = pd.DataFrame(y_pred, columns = ['label'])\n","y_pred_df.reset_index(inplace=True)\n","y_pred_df.rename(columns={'index': 'id'}, inplace=True)\n","y_pred_df[:5]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"qvIpbNYYpcTw","executionInfo":{"status":"ok","timestamp":1680837130299,"user_tz":-540,"elapsed":7,"user":{"displayName":"라크샤사","userId":"01838305003834813418"}},"outputId":"d1b13864-303c-4da1-fbb4-c52ffcc967b2"},"execution_count":96,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   id  label\n","0   0      3\n","1   1      3\n","2   2      0\n","3   3      0\n","4   4      0"],"text/html":["\n","  <div id=\"df-061c6e44-cebd-4a59-ba30-736d77c1834f\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-061c6e44-cebd-4a59-ba30-736d77c1834f')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-061c6e44-cebd-4a59-ba30-736d77c1834f button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-061c6e44-cebd-4a59-ba30-736d77c1834f');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":96}]},{"cell_type":"code","source":["y_pred_df.to_csv('y_pred.csv', index = False)"],"metadata":{"id":"J_ka1ohMqAcj","executionInfo":{"status":"ok","timestamp":1680837158134,"user_tz":-540,"elapsed":982,"user":{"displayName":"라크샤사","userId":"01838305003834813418"}}},"execution_count":98,"outputs":[]},{"cell_type":"code","source":["print(classification_report(y_val, y_pred))"],"metadata":{"id":"vwMbbm5FV1yL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BuMrPRRYtb21"},"source":["### 3-2. Model 2"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nvCKAJW2tb21","executionInfo":{"status":"ok","timestamp":1680759495333,"user_tz":-540,"elapsed":3583,"user":{"displayName":"라크샤사","userId":"01838305003834813418"}},"outputId":"c5e44da2-1362-4ffa-9f17-d230b0cd1cd4"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.7154423639639229"]},"metadata":{},"execution_count":12}],"source":["model_rf = RandomForestClassifier()\n","model_rf.fit(X_tfidf_train, y_train)\n","y_pred = model_rf.predict(X_tfidf_val)\n","f1_score(y_val, y_pred, average = 'weighted')"]},{"cell_type":"markdown","metadata":{"id":"jczSn2_Vtb21"},"source":["### 3-3. Model 3"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"itHSpImstb21","executionInfo":{"status":"ok","timestamp":1680759508296,"user_tz":-540,"elapsed":12965,"user":{"displayName":"라크샤사","userId":"01838305003834813418"}},"outputId":"66fbaf06-60ac-4664-b326-25b17468d779"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.788217162389398"]},"metadata":{},"execution_count":13}],"source":["from sklearn.feature_extraction.text import CountVectorizer\n","\n","X_mor_sequence_train_str = np.array([str(x) for x in X_mor_sequence_train])\n","X_mor_sequence_val_str = np.array([str(x) for x in X_mor_sequence_val])\n","# X_mor_sequence_te_str = np.array([str(x) for x in X_mor_sequence_te])\n","\n","vectorizer = CountVectorizer(ngram_range=(1,2))\n","X_train_ngram = vectorizer.fit_transform(X_mor_sequence_train_str)\n","X_val_ngram = vectorizer.transform(X_mor_sequence_val_str)\n","\n","model_linear.fit(X_train_ngram, y_train)\n","y_pred = model_linear.predict(X_val_ngram)\n","f1_score(y_val, y_pred, average = 'weighted')"]},{"cell_type":"code","source":["from sklearn.svm import SVC\n","\n","model_svm = SVC()\n","model_svm.fit(X_tfidf_train, y_train)\n","y_pred = model_svm.predict(X_tfidf_val)\n","f1_score(y_val, y_pred, average = 'weighted')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"URzCLQ1tTi9W","executionInfo":{"status":"ok","timestamp":1680759513864,"user_tz":-540,"elapsed":5578,"user":{"displayName":"라크샤사","userId":"01838305003834813418"}},"outputId":"81eb2a58-0407-4e4c-d5b7-2d380e9dd994"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.7584122547886745"]},"metadata":{},"execution_count":14}]},{"cell_type":"markdown","source":["### 3-4. Model 4"],"metadata":{"id":"4XlgLhbUb00z"}},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.backend import clear_session\n","from tensorflow.keras.layers import Input, Dense, Embedding, Flatten, Conv1D, LSTM, Dropout\n","from tensorflow.keras.models import Sequential, Model"],"metadata":{"id":"LAaYTQuYUb3x"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_tfidf_train.shape, y_val.shape, y_train.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eesGzjOFUqKb","executionInfo":{"status":"ok","timestamp":1680759513865,"user_tz":-540,"elapsed":14,"user":{"displayName":"라크샤사","userId":"01838305003834813418"}},"outputId":"2f6aaca7-dbc7-443c-fca7-14a2f46ef3ca"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((2084, 62966), (927,), (2084,))"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["clear_session()\n","\n","model = Sequential()\n","\n","model.add(Input(shape = (62966)))\n","model.add(Flatten())\n","model.add(Dense(2048, activation = 'relu'))\n","model.add(Dense(1024, activation = 'relu'))\n","model.add(Dense(512, activation = 'relu'))\n","model.add(Dense(5, activation = 'softmax'))\n","\n","model.compile(loss = keras.losses.sparse_categorical_crossentropy,\n","              optimizer = 'adam',\n","              metrics = 'accuracy')\n","\n","model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6WfwdFkmT6Qt","executionInfo":{"status":"ok","timestamp":1680759517615,"user_tz":-540,"elapsed":3761,"user":{"displayName":"라크샤사","userId":"01838305003834813418"}},"outputId":"54398e0b-1be8-438a-d1b0-c78b064576ac"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," flatten (Flatten)           (None, 62966)             0         \n","                                                                 \n"," dense (Dense)               (None, 2048)              128956416 \n","                                                                 \n"," dense_1 (Dense)             (None, 1024)              2098176   \n","                                                                 \n"," dense_2 (Dense)             (None, 512)               524800    \n","                                                                 \n"," dense_3 (Dense)             (None, 5)                 2565      \n","                                                                 \n","=================================================================\n","Total params: 131,581,957\n","Trainable params: 131,581,957\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["from tensorflow.keras.callbacks import EarlyStopping"],"metadata":{"id":"bfgfEnfGV-aj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["es = EarlyStopping(monitor = 'val_loss',\n","                   min_delta = 0,\n","                   patience = 5,\n","                   restore_best_weights = True)\n","model.fit(X_tfidf_train.toarray(), y_train, validation_data = (X_tfidf_val.toarray(), y_val), verbose = 1, epochs = 100, callbacks = [es])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_wfBrMw3VSlj","executionInfo":{"status":"ok","timestamp":1680759541048,"user_tz":-540,"elapsed":23444,"user":{"displayName":"라크샤사","userId":"01838305003834813418"}},"outputId":"7046f6a6-ba29-445d-f092-6eb5179b28da"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","66/66 [==============================] - 10s 63ms/step - loss: 0.9571 - accuracy: 0.6291 - val_loss: 0.6184 - val_accuracy: 0.7875\n","Epoch 2/100\n","66/66 [==============================] - 2s 35ms/step - loss: 0.0681 - accuracy: 0.9794 - val_loss: 0.9427 - val_accuracy: 0.7961\n","Epoch 3/100\n","66/66 [==============================] - 2s 37ms/step - loss: 0.0058 - accuracy: 0.9986 - val_loss: 0.8693 - val_accuracy: 0.8101\n","Epoch 4/100\n","66/66 [==============================] - 2s 32ms/step - loss: 1.4763e-04 - accuracy: 1.0000 - val_loss: 0.9127 - val_accuracy: 0.8112\n","Epoch 5/100\n","66/66 [==============================] - 2s 32ms/step - loss: 6.1100e-05 - accuracy: 1.0000 - val_loss: 0.9423 - val_accuracy: 0.8145\n","Epoch 6/100\n","66/66 [==============================] - 3s 40ms/step - loss: 3.4713e-05 - accuracy: 1.0000 - val_loss: 0.9648 - val_accuracy: 0.8145\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f0607e98640>"]},"metadata":{},"execution_count":19}]},{"cell_type":"code","source":["y_pred = model.predict(X_tfidf_val.toarray())\n","confusion_matrix(y_val, y_pred)\n","classification_report(y_val, y_pred)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":432},"id":"pI78CmqTVVa6","executionInfo":{"status":"error","timestamp":1680759546181,"user_tz":-540,"elapsed":2279,"user":{"displayName":"라크샤사","userId":"01838305003834813418"}},"outputId":"9c2eb404-949a-4242-cc5e-21749578d02e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["29/29 [==============================] - 0s 9ms/step\n"]},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-20-6deec4c24ba3>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_tfidf_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mconfusion_matrix\u001b[0;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[1;32m    315\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m     \"\"\"\n\u001b[0;32m--> 317\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    318\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s is not supported\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m     96\u001b[0m             \"Classification metrics can't handle a mix of {0} and {1} targets\".format(\n\u001b[1;32m     97\u001b[0m                 \u001b[0mtype_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of multiclass and continuous-multioutput targets"]}]},{"cell_type":"markdown","source":["### 3-5. Model 5"],"metadata":{"id":"g_T921dlnHhr"}},{"cell_type":"code","source":["from lightgbm import LGBMClassifier\n","\n","model_lgbm = LGBMClassifier(n_estimators=500, max_depth=9, min_child_weight=5, n_jobs=-1)\n","model_lgbm.fit(X_tfidf_train, y_train)\n","y_pred = model_lgbm.predict(X_tfidf_val)\n","f1_score(y_val, y_pred, average = 'weighted')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AfEXYBwOnKXq","executionInfo":{"status":"ok","timestamp":1680846620908,"user_tz":-540,"elapsed":5159,"user":{"displayName":"라크샤사","userId":"01838305003834813418"}},"outputId":"9062ea74-c29d-4fc5-b183-9cb5129475c6"},"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.7396517856114904"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","source":["!pip install optuna"],"metadata":{"id":"SqHwYWqNRwt2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import mean_squared_error"],"metadata":{"id":"4a1_fhfEUCbn","executionInfo":{"status":"ok","timestamp":1680847418590,"user_tz":-540,"elapsed":873,"user":{"displayName":"라크샤사","userId":"01838305003834813418"}}},"execution_count":34,"outputs":[]},{"cell_type":"code","source":["def RMSE(y, y_pred):\n","    rmse = mean_squared_error(y, y_pred) ** 0.5\n","    return rmse"],"metadata":{"id":"o22k-pDlT0e0","executionInfo":{"status":"ok","timestamp":1680847381587,"user_tz":-540,"elapsed":653,"user":{"displayName":"라크샤사","userId":"01838305003834813418"}}},"execution_count":32,"outputs":[]},{"cell_type":"code","source":["from optuna.samplers import TPESampler\n","import optuna\n","from optuna.integration import XGBoostPruningCallback\n","import lightgbm as lgb\n","\n","sampler = TPESampler(seed = 10)\n","\n","\n","def objective(trial):\n","    dtrain = lgb.Dataset(X_tfidf_train, label=y_train)\n","    dtest = lgb.Dataset(X_tfidf_val, label=y_val)\n","\n","    param = {\n","        'objective': 'multiclass', # 회귀\n","        'verbose': -1,\n","        'metric': None, \n","        'max_depth': trial.suggest_int('max_depth',3, 15),\n","        'learning_rate': trial.suggest_loguniform(\"learning_rate\", 1e-8, 1e-2),\n","        'n_estimators': trial.suggest_int('n_estimators', 100, 3000),\n","        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n","        'subsample': trial.suggest_loguniform('subsample', 0.4, 1),\n","    }\n","\n","    model = lgb.LGBMClassifier(**param)\n","    lgb_model = model.fit(X_tfidf_train, y_train, eval_set=[(X_tfidf_val, y_val)], verbose=0, early_stopping_rounds=25)\n","    y_pred = lgb_model.predict(X_tfidf_val)\n","    f1_macro = f1_score(y_val, y_pred, average='macro')\n","    return f1_macro\n","\n","study_lgb = optuna.create_study(direction='maximize', sampler=sampler)\n","study_lgb.optimize(objective, n_trials=100)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"ixBZ34p8RKbE","executionInfo":{"status":"error","timestamp":1680848249276,"user_tz":-540,"elapsed":487883,"user":{"displayName":"라크샤사","userId":"01838305003834813418"}},"outputId":"f448d0bc-536d-4181-d935-916be8edb59f"},"execution_count":36,"outputs":[{"output_type":"stream","name":"stderr","text":["\u001b[32m[I 2023-04-07 06:09:19,652]\u001b[0m A new study created in memory with name: no-name-48865dca-5c83-49d1-a6e1-51fca9f22b30\u001b[0m\n","<ipython-input-36-642066095754>:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n","  'learning_rate': trial.suggest_loguniform(\"learning_rate\", 1e-8, 1e-2),\n","<ipython-input-36-642066095754>:21: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n","  'subsample': trial.suggest_loguniform('subsample', 0.4, 1),\n","/usr/local/lib/python3.9/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n","  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n","/usr/local/lib/python3.9/dist-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n","  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n","\u001b[32m[I 2023-04-07 06:09:51,082]\u001b[0m Trial 0 finished with value: 0.11887793783169068 and parameters: {'max_depth': 13, 'learning_rate': 1.3320229150659043e-08, 'n_estimators': 1938, 'min_child_samples': 76, 'subsample': 0.6315909175774905}. Best is trial 0 with value: 0.11887793783169068.\u001b[0m\n","<ipython-input-36-642066095754>:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n","  'learning_rate': trial.suggest_loguniform(\"learning_rate\", 1e-8, 1e-2),\n","<ipython-input-36-642066095754>:21: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n","  'subsample': trial.suggest_loguniform('subsample', 0.4, 1),\n","/usr/local/lib/python3.9/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n","  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n","/usr/local/lib/python3.9/dist-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n","  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n","\u001b[32m[I 2023-04-07 06:10:28,464]\u001b[0m Trial 1 finished with value: 0.11887793783169068 and parameters: {'max_depth': 5, 'learning_rate': 1.5430400149097381e-07, 'n_estimators': 2306, 'min_child_samples': 21, 'subsample': 0.4337244827306443}. Best is trial 0 with value: 0.11887793783169068.\u001b[0m\n","<ipython-input-36-642066095754>:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n","  'learning_rate': trial.suggest_loguniform(\"learning_rate\", 1e-8, 1e-2),\n","<ipython-input-36-642066095754>:21: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n","  'subsample': trial.suggest_loguniform('subsample', 0.4, 1),\n","/usr/local/lib/python3.9/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n","  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n","/usr/local/lib/python3.9/dist-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n","  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n","\u001b[32m[I 2023-04-07 06:10:30,521]\u001b[0m Trial 2 finished with value: 0.6002010387685246 and parameters: {'max_depth': 11, 'learning_rate': 0.005252427629146827, 'n_estimators': 111, 'min_child_samples': 54, 'subsample': 0.8422371309477078}. Best is trial 2 with value: 0.6002010387685246.\u001b[0m\n","<ipython-input-36-642066095754>:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n","  'learning_rate': trial.suggest_loguniform(\"learning_rate\", 1e-8, 1e-2),\n","<ipython-input-36-642066095754>:21: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n","  'subsample': trial.suggest_loguniform('subsample', 0.4, 1),\n","/usr/local/lib/python3.9/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n","  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n","/usr/local/lib/python3.9/dist-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n","  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n","\u001b[32m[I 2023-04-07 06:10:43,297]\u001b[0m Trial 3 finished with value: 0.11887793783169068 and parameters: {'max_depth': 10, 'learning_rate': 0.00021405821746591817, 'n_estimators': 946, 'min_child_samples': 93, 'subsample': 0.7698715745641292}. Best is trial 2 with value: 0.6002010387685246.\u001b[0m\n","<ipython-input-36-642066095754>:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n","  'learning_rate': trial.suggest_loguniform(\"learning_rate\", 1e-8, 1e-2),\n","<ipython-input-36-642066095754>:21: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n","  'subsample': trial.suggest_loguniform('subsample', 0.4, 1),\n","/usr/local/lib/python3.9/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n","  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n","/usr/local/lib/python3.9/dist-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n","  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n","\u001b[32m[I 2023-04-07 06:11:03,676]\u001b[0m Trial 4 finished with value: 0.11887793783169068 and parameters: {'max_depth': 10, 'learning_rate': 7.128863277996207e-08, 'n_estimators': 1183, 'min_child_samples': 69, 'subsample': 0.5996296351455978}. Best is trial 2 with value: 0.6002010387685246.\u001b[0m\n","<ipython-input-36-642066095754>:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n","  'learning_rate': trial.suggest_loguniform(\"learning_rate\", 1e-8, 1e-2),\n","<ipython-input-36-642066095754>:21: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n","  'subsample': trial.suggest_loguniform('subsample', 0.4, 1),\n","/usr/local/lib/python3.9/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n","  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n","/usr/local/lib/python3.9/dist-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n","  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n","\u001b[32m[I 2023-04-07 06:11:27,443]\u001b[0m Trial 5 finished with value: 0.11887793783169068 and parameters: {'max_depth': 8, 'learning_rate': 5.08864167992051e-05, 'n_estimators': 1588, 'min_child_samples': 67, 'subsample': 0.6938050197112922}. Best is trial 2 with value: 0.6002010387685246.\u001b[0m\n","<ipython-input-36-642066095754>:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n","  'learning_rate': trial.suggest_loguniform(\"learning_rate\", 1e-8, 1e-2),\n","<ipython-input-36-642066095754>:21: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n","  'subsample': trial.suggest_loguniform('subsample', 0.4, 1),\n","/usr/local/lib/python3.9/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n","  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n","/usr/local/lib/python3.9/dist-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n","  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n","\u001b[32m[I 2023-04-07 06:12:52,269]\u001b[0m Trial 6 finished with value: 0.11887793783169068 and parameters: {'max_depth': 13, 'learning_rate': 1.3485992516968212e-05, 'n_estimators': 2735, 'min_child_samples': 35, 'subsample': 0.4345676420333751}. Best is trial 2 with value: 0.6002010387685246.\u001b[0m\n","<ipython-input-36-642066095754>:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n","  'learning_rate': trial.suggest_loguniform(\"learning_rate\", 1e-8, 1e-2),\n","<ipython-input-36-642066095754>:21: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n","  'subsample': trial.suggest_loguniform('subsample', 0.4, 1),\n","/usr/local/lib/python3.9/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n","  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n","/usr/local/lib/python3.9/dist-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n","  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n","\u001b[32m[I 2023-04-07 06:14:01,737]\u001b[0m Trial 7 finished with value: 0.11887793783169068 and parameters: {'max_depth': 6, 'learning_rate': 4.8295444901938926e-08, 'n_estimators': 2504, 'min_child_samples': 9, 'subsample': 0.7100430887666348}. Best is trial 2 with value: 0.6002010387685246.\u001b[0m\n","<ipython-input-36-642066095754>:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n","  'learning_rate': trial.suggest_loguniform(\"learning_rate\", 1e-8, 1e-2),\n","<ipython-input-36-642066095754>:21: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n","  'subsample': trial.suggest_loguniform('subsample', 0.4, 1),\n","/usr/local/lib/python3.9/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n","  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n","/usr/local/lib/python3.9/dist-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n","  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n","\u001b[32m[I 2023-04-07 06:14:11,743]\u001b[0m Trial 8 finished with value: 0.36393423036175165 and parameters: {'max_depth': 10, 'learning_rate': 0.0008236106883720722, 'n_estimators': 677, 'min_child_samples': 87, 'subsample': 0.5520731753100153}. Best is trial 2 with value: 0.6002010387685246.\u001b[0m\n","<ipython-input-36-642066095754>:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n","  'learning_rate': trial.suggest_loguniform(\"learning_rate\", 1e-8, 1e-2),\n","<ipython-input-36-642066095754>:21: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n","  'subsample': trial.suggest_loguniform('subsample', 0.4, 1),\n","/usr/local/lib/python3.9/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n","  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n","/usr/local/lib/python3.9/dist-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n","  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n","\u001b[32m[I 2023-04-07 06:15:29,942]\u001b[0m Trial 9 finished with value: 0.11887793783169068 and parameters: {'max_depth': 12, 'learning_rate': 5.967195151630884e-07, 'n_estimators': 2664, 'min_child_samples': 36, 'subsample': 0.46529289303849874}. Best is trial 2 with value: 0.6002010387685246.\u001b[0m\n","<ipython-input-36-642066095754>:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n","  'learning_rate': trial.suggest_loguniform(\"learning_rate\", 1e-8, 1e-2),\n","<ipython-input-36-642066095754>:21: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n","  'subsample': trial.suggest_loguniform('subsample', 0.4, 1),\n","/usr/local/lib/python3.9/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n","  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n","/usr/local/lib/python3.9/dist-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n","  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n","\u001b[32m[I 2023-04-07 06:15:30,772]\u001b[0m Trial 10 finished with value: 0.5860469489303702 and parameters: {'max_depth': 3, 'learning_rate': 0.007287079614451871, 'n_estimators': 125, 'min_child_samples': 50, 'subsample': 0.9370978022952945}. Best is trial 2 with value: 0.6002010387685246.\u001b[0m\n","<ipython-input-36-642066095754>:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n","  'learning_rate': trial.suggest_loguniform(\"learning_rate\", 1e-8, 1e-2),\n","<ipython-input-36-642066095754>:21: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n","  'subsample': trial.suggest_loguniform('subsample', 0.4, 1),\n","/usr/local/lib/python3.9/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n","  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n","/usr/local/lib/python3.9/dist-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n","  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n","\u001b[32m[I 2023-04-07 06:15:31,626]\u001b[0m Trial 11 finished with value: 0.6697514633611649 and parameters: {'max_depth': 3, 'learning_rate': 0.009781360056777894, 'n_estimators': 134, 'min_child_samples': 50, 'subsample': 0.9710017015068795}. Best is trial 11 with value: 0.6697514633611649.\u001b[0m\n","<ipython-input-36-642066095754>:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n","  'learning_rate': trial.suggest_loguniform(\"learning_rate\", 1e-8, 1e-2),\n","<ipython-input-36-642066095754>:21: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n","  'subsample': trial.suggest_loguniform('subsample', 0.4, 1),\n","/usr/local/lib/python3.9/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n","  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n","/usr/local/lib/python3.9/dist-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n","  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n","\u001b[32m[I 2023-04-07 06:15:34,802]\u001b[0m Trial 12 finished with value: 0.6364069133165251 and parameters: {'max_depth': 3, 'learning_rate': 0.007773589322284729, 'n_estimators': 151, 'min_child_samples': 50, 'subsample': 0.9988113820538725}. Best is trial 11 with value: 0.6697514633611649.\u001b[0m\n","<ipython-input-36-642066095754>:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n","  'learning_rate': trial.suggest_loguniform(\"learning_rate\", 1e-8, 1e-2),\n","<ipython-input-36-642066095754>:21: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n","  'subsample': trial.suggest_loguniform('subsample', 0.4, 1),\n","/usr/local/lib/python3.9/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n","  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n","/usr/local/lib/python3.9/dist-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n","  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n","\u001b[32m[I 2023-04-07 06:15:37,972]\u001b[0m Trial 13 finished with value: 0.7576613564800573 and parameters: {'max_depth': 3, 'learning_rate': 0.009888319202599477, 'n_estimators': 544, 'min_child_samples': 49, 'subsample': 0.9537322871331387}. Best is trial 13 with value: 0.7576613564800573.\u001b[0m\n","<ipython-input-36-642066095754>:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n","  'learning_rate': trial.suggest_loguniform(\"learning_rate\", 1e-8, 1e-2),\n","<ipython-input-36-642066095754>:21: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n","  'subsample': trial.suggest_loguniform('subsample', 0.4, 1),\n","/usr/local/lib/python3.9/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n","  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n","/usr/local/lib/python3.9/dist-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n","  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n","\u001b[32m[I 2023-04-07 06:15:55,204]\u001b[0m Trial 14 finished with value: 0.5647345206589895 and parameters: {'max_depth': 15, 'learning_rate': 0.0007953098131062772, 'n_estimators': 579, 'min_child_samples': 34, 'subsample': 0.8787981219847804}. Best is trial 13 with value: 0.7576613564800573.\u001b[0m\n","<ipython-input-36-642066095754>:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n","  'learning_rate': trial.suggest_loguniform(\"learning_rate\", 1e-8, 1e-2),\n","<ipython-input-36-642066095754>:21: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n","  'subsample': trial.suggest_loguniform('subsample', 0.4, 1),\n","/usr/local/lib/python3.9/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n","  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n","/usr/local/lib/python3.9/dist-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n","  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n","\u001b[32m[I 2023-04-07 06:16:03,198]\u001b[0m Trial 15 finished with value: 0.5078305181872454 and parameters: {'max_depth': 5, 'learning_rate': 0.0007694971413933516, 'n_estimators': 626, 'min_child_samples': 58, 'subsample': 0.9802388051912547}. Best is trial 13 with value: 0.7576613564800573.\u001b[0m\n","<ipython-input-36-642066095754>:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n","  'learning_rate': trial.suggest_loguniform(\"learning_rate\", 1e-8, 1e-2),\n","<ipython-input-36-642066095754>:21: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n","  'subsample': trial.suggest_loguniform('subsample', 0.4, 1),\n","/usr/local/lib/python3.9/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n","  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n","/usr/local/lib/python3.9/dist-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n","  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n","\u001b[32m[I 2023-04-07 06:16:26,624]\u001b[0m Trial 16 finished with value: 0.11887793783169068 and parameters: {'max_depth': 7, 'learning_rate': 4.268833563329448e-06, 'n_estimators': 1261, 'min_child_samples': 41, 'subsample': 0.8383655225381748}. Best is trial 13 with value: 0.7576613564800573.\u001b[0m\n","<ipython-input-36-642066095754>:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n","  'learning_rate': trial.suggest_loguniform(\"learning_rate\", 1e-8, 1e-2),\n","<ipython-input-36-642066095754>:21: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n","  'subsample': trial.suggest_loguniform('subsample', 0.4, 1),\n","/usr/local/lib/python3.9/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n","  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n","/usr/local/lib/python3.9/dist-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n","  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n","\u001b[32m[I 2023-04-07 06:16:32,637]\u001b[0m Trial 17 finished with value: 0.6688834106514031 and parameters: {'max_depth': 4, 'learning_rate': 0.001974490171605893, 'n_estimators': 480, 'min_child_samples': 16, 'subsample': 0.9070340852408912}. Best is trial 13 with value: 0.7576613564800573.\u001b[0m\n","<ipython-input-36-642066095754>:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n","  'learning_rate': trial.suggest_loguniform(\"learning_rate\", 1e-8, 1e-2),\n","<ipython-input-36-642066095754>:21: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n","  'subsample': trial.suggest_loguniform('subsample', 0.4, 1),\n","/usr/local/lib/python3.9/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n","  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n","/usr/local/lib/python3.9/dist-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n","  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n","\u001b[32m[I 2023-04-07 06:16:56,755]\u001b[0m Trial 18 finished with value: 0.11887793783169068 and parameters: {'max_depth': 7, 'learning_rate': 0.0001260244839787028, 'n_estimators': 964, 'min_child_samples': 23, 'subsample': 0.8052056675821299}. Best is trial 13 with value: 0.7576613564800573.\u001b[0m\n","<ipython-input-36-642066095754>:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n","  'learning_rate': trial.suggest_loguniform(\"learning_rate\", 1e-8, 1e-2),\n","<ipython-input-36-642066095754>:21: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n","  'subsample': trial.suggest_loguniform('subsample', 0.4, 1),\n","/usr/local/lib/python3.9/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n","  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n","/usr/local/lib/python3.9/dist-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n","  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n","\u001b[32m[I 2023-04-07 06:16:58,786]\u001b[0m Trial 19 finished with value: 0.5800394373889503 and parameters: {'max_depth': 3, 'learning_rate': 0.00936078035561635, 'n_estimators': 385, 'min_child_samples': 81, 'subsample': 0.9267915036418813}. Best is trial 13 with value: 0.7576613564800573.\u001b[0m\n","<ipython-input-36-642066095754>:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n","  'learning_rate': trial.suggest_loguniform(\"learning_rate\", 1e-8, 1e-2),\n","<ipython-input-36-642066095754>:21: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n","  'subsample': trial.suggest_loguniform('subsample', 0.4, 1),\n","/usr/local/lib/python3.9/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n","  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n","/usr/local/lib/python3.9/dist-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n","  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n","\u001b[32m[I 2023-04-07 06:17:17,240]\u001b[0m Trial 20 finished with value: 0.6242602616645956 and parameters: {'max_depth': 5, 'learning_rate': 0.002445072437345344, 'n_estimators': 1686, 'min_child_samples': 61, 'subsample': 0.7661512331787581}. Best is trial 13 with value: 0.7576613564800573.\u001b[0m\n","<ipython-input-36-642066095754>:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n","  'learning_rate': trial.suggest_loguniform(\"learning_rate\", 1e-8, 1e-2),\n","<ipython-input-36-642066095754>:21: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n","  'subsample': trial.suggest_loguniform('subsample', 0.4, 1),\n","/usr/local/lib/python3.9/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n","  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n","/usr/local/lib/python3.9/dist-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n","  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n","\u001b[33m[W 2023-04-07 06:17:26,891]\u001b[0m Trial 21 failed with parameters: {'max_depth': 4, 'learning_rate': 0.0015289766957640428, 'n_estimators': 436, 'min_child_samples': 5, 'subsample': 0.9015733524857866} because of the following error: KeyboardInterrupt().\u001b[0m\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.9/dist-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n","    value_or_values = func(trial)\n","  File \"<ipython-input-36-642066095754>\", line 25, in objective\n","    lgb_model = model.fit(X_tfidf_train, y_train, eval_set=[(X_tfidf_val, y_val)], verbose=0, early_stopping_rounds=25)\n","  File \"/usr/local/lib/python3.9/dist-packages/lightgbm/sklearn.py\", line 967, in fit\n","    super().fit(X, _y, sample_weight=sample_weight, init_score=init_score, eval_set=valid_sets,\n","  File \"/usr/local/lib/python3.9/dist-packages/lightgbm/sklearn.py\", line 748, in fit\n","    self._Booster = train(\n","  File \"/usr/local/lib/python3.9/dist-packages/lightgbm/engine.py\", line 292, in train\n","    booster.update(fobj=fobj)\n","  File \"/usr/local/lib/python3.9/dist-packages/lightgbm/basic.py\", line 3021, in update\n","    _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n","KeyboardInterrupt\n","\u001b[33m[W 2023-04-07 06:17:26,897]\u001b[0m Trial 21 failed with value None.\u001b[0m\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-36-642066095754>\u001b[0m in \u001b[0;36m<cell line: 31>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0mstudy_lgb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'maximize'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msampler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0mstudy_lgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/optuna/study/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    423\u001b[0m         \"\"\"\n\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m         _optimize(\n\u001b[0m\u001b[1;32m    426\u001b[0m             \u001b[0mstudy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m             _optimize_sequential(\n\u001b[0m\u001b[1;32m     67\u001b[0m                 \u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             \u001b[0mfrozen_trial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0;31m# The following line mitigates memory problems that can be occurred in some\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     ):\n\u001b[0;32m--> 251\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfunc_err\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfrozen_trial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mget_heartbeat_thread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trial_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m             \u001b[0mvalue_or_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-36-642066095754>\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLGBMClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mlgb_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_tfidf_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_tfidf_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlgb_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_tfidf_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mf1_macro\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'macro'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[1;32m    965\u001b[0m                     \u001b[0mvalid_sets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mvalid_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_le\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 967\u001b[0;31m         super().fit(X, _y, sample_weight=sample_weight, init_score=init_score, eval_set=valid_sets,\n\u001b[0m\u001b[1;32m    968\u001b[0m                     \u001b[0meval_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_sample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_sample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    969\u001b[0m                     \u001b[0meval_class_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_class_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_init_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_init_score\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[1;32m    746\u001b[0m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord_evaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    747\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 748\u001b[0;31m         self._Booster = train(\n\u001b[0m\u001b[1;32m    749\u001b[0m             \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m             \u001b[0mtrain_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    290\u001b[0m                                     evaluation_result_list=None))\n\u001b[1;32m    291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m         \u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, train_set, fobj)\u001b[0m\n\u001b[1;32m   3019\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__set_objective_to_none\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3020\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mLightGBMError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Cannot update due to null objective function.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3021\u001b[0;31m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[0m\u001b[1;32m   3022\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3023\u001b[0m                 ctypes.byref(is_finished)))\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["trial = study_lgb.best_trial\n","trial_params = trial.params\n","print('Best Trial: score {},\\nparams {}'.format(trial.value, trial_params))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xprhRaGiVoGN","executionInfo":{"status":"ok","timestamp":1680848255729,"user_tz":-540,"elapsed":806,"user":{"displayName":"라크샤사","userId":"01838305003834813418"}},"outputId":"f6aa9b9f-275b-49df-84f5-42d2da7f2ea0"},"execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["Best Trial: score 0.7576613564800573,\n","params {'max_depth': 3, 'learning_rate': 0.009888319202599477, 'n_estimators': 544, 'min_child_samples': 49, 'subsample': 0.9537322871331387}\n"]}]},{"cell_type":"markdown","metadata":{"id":"fO2lvJmhtb21"},"source":["### 3-6. Hyperparameter Tuning(Optional) \n","* Manual Search, Grid search, Bayesian Optimization, TPE...\n","> * [grid search tutorial sklearn](https://scikit-learn.org/stable/modules/grid_search.html)\n","> * [optuna tutorial](https://optuna.org/#code_examples)\n","> * [ray-tune tutorial](https://docs.ray.io/en/latest/tune/examples/tune-sklearn.html)"]},{"cell_type":"code","source":["!pip install bayesian-optimization"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HQyM-4hD5_Dz","executionInfo":{"status":"ok","timestamp":1680831645506,"user_tz":-540,"elapsed":7326,"user":{"displayName":"라크샤사","userId":"01838305003834813418"}},"outputId":"89489efc-a2a2-45eb-9d3e-b39788abe4ee"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting bayesian-optimization\n","  Downloading bayesian_optimization-1.4.2-py3-none-any.whl (17 kB)\n","Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.9/dist-packages (from bayesian-optimization) (1.22.4)\n","Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from bayesian-optimization) (1.10.1)\n","Collecting colorama>=0.4.6\n","  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n","Requirement already satisfied: scikit-learn>=0.18.0 in /usr/local/lib/python3.9/dist-packages (from bayesian-optimization) (1.2.2)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.18.0->bayesian-optimization) (1.1.1)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.18.0->bayesian-optimization) (3.1.0)\n","Installing collected packages: colorama, bayesian-optimization\n","Successfully installed bayesian-optimization-1.4.2 colorama-0.4.6\n"]}]},{"cell_type":"code","execution_count":15,"metadata":{"id":"Al5k-RSjtb21","executionInfo":{"status":"ok","timestamp":1680831645507,"user_tz":-540,"elapsed":4,"user":{"displayName":"라크샤사","userId":"01838305003834813418"}}},"outputs":[],"source":["from bayes_opt import BayesianOptimization\n","from sklearn.model_selection import GridSearchCV"]},{"cell_type":"code","source":["model = LogisticRegression()\n","\n","params ={\n","    'C': [0.001, 0.01, 0.1, 1, 10, 100]\n","}\n","\n","grid_search = GridSearchCV(model,\n","                           params, \n","                           cv=5,\n","                           scoring = 'f1')\n","\n","grid_search.fit(X_tfidf_train, y_train)\n","\n","best_model = grid_search.best_estimator_\n","best_model.fit(X_tfidf_train, y_train)\n","\n","# 테스트 데이터에 대한 예측 및 평가\n","y_pred = best_model.predict(X_tfidf_val)\n","f1 = f1_score(y_val, y_pred, average = 'weighted')\n","print(f\"F1-score: {f1}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JxlXd9z14fxj","executionInfo":{"status":"ok","timestamp":1680832163568,"user_tz":-540,"elapsed":29475,"user":{"displayName":"라크샤사","userId":"01838305003834813418"}},"outputId":"8138f93f-1490-4e96-d7ad-3acf966b36fe"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n","    scores = scorer(estimator, X_test, y_test)\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n","    return self._score(\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_scorer.py\", line 282, in _score\n","    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py\", line 1146, in f1_score\n","    return fbeta_score(\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py\", line 1287, in fbeta_score\n","    _, _, f, _ = precision_recall_fscore_support(\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py\", line 1573, in precision_recall_fscore_support\n","    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py\", line 1391, in _check_set_wise_labels\n","    raise ValueError(\n","ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n","\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n","    scores = scorer(estimator, X_test, y_test)\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n","    return self._score(\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_scorer.py\", line 282, in _score\n","    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py\", line 1146, in f1_score\n","    return fbeta_score(\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py\", line 1287, in fbeta_score\n","    _, _, f, _ = precision_recall_fscore_support(\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py\", line 1573, in precision_recall_fscore_support\n","    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py\", line 1391, in _check_set_wise_labels\n","    raise ValueError(\n","ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n","\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n","    scores = scorer(estimator, X_test, y_test)\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n","    return self._score(\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_scorer.py\", line 282, in _score\n","    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py\", line 1146, in f1_score\n","    return fbeta_score(\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py\", line 1287, in fbeta_score\n","    _, _, f, _ = precision_recall_fscore_support(\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py\", line 1573, in precision_recall_fscore_support\n","    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py\", line 1391, in _check_set_wise_labels\n","    raise ValueError(\n","ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n","\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n","    scores = scorer(estimator, X_test, y_test)\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n","    return self._score(\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_scorer.py\", line 282, in _score\n","    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py\", line 1146, in f1_score\n","    return fbeta_score(\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py\", line 1287, in fbeta_score\n","    _, _, f, _ = precision_recall_fscore_support(\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py\", line 1573, in precision_recall_fscore_support\n","    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py\", line 1391, in _check_set_wise_labels\n","    raise ValueError(\n","ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n","\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n","    scores = scorer(estimator, X_test, y_test)\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n","    return self._score(\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_scorer.py\", line 282, in _score\n","    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py\", line 1146, in f1_score\n","    return fbeta_score(\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py\", line 1287, in fbeta_score\n","    _, _, f, _ = precision_recall_fscore_support(\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py\", line 1573, in precision_recall_fscore_support\n","    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py\", line 1391, in _check_set_wise_labels\n","    raise ValueError(\n","ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n","\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n","    scores = scorer(estimator, X_test, y_test)\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n","    return self._score(\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_scorer.py\", line 282, in _score\n","    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py\", line 1146, in f1_score\n","    return fbeta_score(\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py\", line 1287, in fbeta_score\n","    _, _, f, _ = precision_recall_fscore_support(\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py\", line 1573, in precision_recall_fscore_support\n","    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py\", line 1391, in _check_set_wise_labels\n","    raise ValueError(\n","ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n","\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n","    scores = scorer(estimator, X_test, y_test)\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n","    return self._score(\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_scorer.py\", line 282, in _score\n","    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py\", line 1146, in f1_score\n","    return fbeta_score(\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py\", line 1287, in fbeta_score\n","    _, _, f, _ = precision_recall_fscore_support(\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py\", line 1573, in precision_recall_fscore_support\n","    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py\", line 1391, in _check_set_wise_labels\n","    raise ValueError(\n","ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n","\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n","    scores = scorer(estimator, X_test, y_test)\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n","    return self._score(\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_scorer.py\", line 282, in _score\n","    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py\", line 1146, in f1_score\n","    return fbeta_score(\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py\", line 1287, in fbeta_score\n","    _, _, f, _ = precision_recall_fscore_support(\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py\", line 1573, in precision_recall_fscore_support\n","    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py\", line 1391, in _check_set_wise_labels\n","    raise ValueError(\n","ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n","\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n","    scores = scorer(estimator, X_test, y_test)\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n","    return self._score(\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_scorer.py\", line 282, in _score\n","    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py\", line 1146, in f1_score\n","    return fbeta_score(\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py\", line 1287, in fbeta_score\n","    _, _, f, _ = precision_recall_fscore_support(\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py\", line 1573, in precision_recall_fscore_support\n","    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py\", line 1391, in _check_set_wise_labels\n","    raise ValueError(\n","ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n","\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n","    scores = scorer(estimator, X_test, y_test)\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n","    return self._score(\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_scorer.py\", line 282, in _score\n","    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py\", line 1146, in f1_score\n","    return fbeta_score(\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py\", line 1287, in fbeta_score\n","    _, _, f, _ = precision_recall_fscore_support(\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py\", line 1573, in precision_recall_fscore_support\n","    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py\", line 1391, in _check_set_wise_labels\n","    raise ValueError(\n","ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n","\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n","    scores = scorer(estimator, X_test, y_test)\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n","    return self._score(\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_scorer.py\", line 282, in _score\n","    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py\", line 1146, in f1_score\n","    return fbeta_score(\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py\", line 1287, in fbeta_score\n","    _, _, f, _ = precision_recall_fscore_support(\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py\", line 1573, in precision_recall_fscore_support\n","    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py\", line 1391, in _check_set_wise_labels\n","    raise ValueError(\n","ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n","\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n","    scores = scorer(estimator, X_test, y_test)\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n","    return self._score(\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_scorer.py\", line 282, in _score\n","    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py\", line 1146, in f1_score\n","    return fbeta_score(\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py\", line 1287, in fbeta_score\n","    _, _, f, _ = precision_recall_fscore_support(\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py\", line 1573, in precision_recall_fscore_support\n","    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py\", line 1391, in _check_set_wise_labels\n","    raise ValueError(\n","ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n","\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n","    scores = scorer(estimator, X_test, y_test)\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n","    return self._score(\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_scorer.py\", line 282, in _score\n","    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py\", line 1146, in f1_score\n","    return fbeta_score(\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py\", line 1287, in fbeta_score\n","    _, _, f, _ = precision_recall_fscore_support(\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py\", line 1573, in precision_recall_fscore_support\n","    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py\", line 1391, in _check_set_wise_labels\n","    raise ValueError(\n","ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n","\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n","    scores = scorer(estimator, X_test, y_test)\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n","    return self._score(\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_scorer.py\", line 282, in _score\n","    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py\", line 1146, in f1_score\n","    return fbeta_score(\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py\", line 1287, in fbeta_score\n","    _, _, f, _ = precision_recall_fscore_support(\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py\", line 1573, in precision_recall_fscore_support\n","    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py\", line 1391, in _check_set_wise_labels\n","    raise ValueError(\n","ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n","\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n","    scores = scorer(estimator, X_test, y_test)\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n","    return self._score(\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_scorer.py\", line 282, in _score\n","    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py\", line 1146, in f1_score\n","    return fbeta_score(\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py\", line 1287, in fbeta_score\n","    _, _, f, _ = precision_recall_fscore_support(\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py\", line 1573, in precision_recall_fscore_support\n","    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py\", line 1391, in _check_set_wise_labels\n","    raise ValueError(\n","ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n","\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n","    scores = scorer(estimator, X_test, y_test)\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n","    return self._score(\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_scorer.py\", line 282, in _score\n","    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py\", line 1146, in f1_score\n","    return fbeta_score(\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py\", line 1287, in fbeta_score\n","    _, _, f, _ = precision_recall_fscore_support(\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py\", line 1573, in precision_recall_fscore_support\n","    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py\", line 1391, in _check_set_wise_labels\n","    raise ValueError(\n","ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n","\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n","    scores = scorer(estimator, X_test, y_test)\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n","    return self._score(\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_scorer.py\", line 282, in _score\n","    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py\", line 1146, in f1_score\n","    return fbeta_score(\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py\", line 1287, in fbeta_score\n","    _, _, f, _ = precision_recall_fscore_support(\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py\", line 1573, in precision_recall_fscore_support\n","    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py\", line 1391, in _check_set_wise_labels\n","    raise ValueError(\n","ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n","\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n","    scores = scorer(estimator, X_test, y_test)\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n","    return self._score(\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_scorer.py\", line 282, in _score\n","    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py\", line 1146, in f1_score\n","    return fbeta_score(\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py\", line 1287, in fbeta_score\n","    _, _, f, _ = precision_recall_fscore_support(\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py\", line 1573, in precision_recall_fscore_support\n","    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py\", line 1391, in _check_set_wise_labels\n","    raise ValueError(\n","ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n","\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n","    scores = scorer(estimator, X_test, y_test)\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n","    return self._score(\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_scorer.py\", line 282, in _score\n","    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py\", line 1146, in f1_score\n","    return fbeta_score(\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py\", line 1287, in fbeta_score\n","    _, _, f, _ = precision_recall_fscore_support(\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py\", line 1573, in precision_recall_fscore_support\n","    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py\", line 1391, in _check_set_wise_labels\n","    raise ValueError(\n","ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n","\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n","    scores = scorer(estimator, X_test, y_test)\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n","    return self._score(\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_scorer.py\", line 282, in _score\n","    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py\", line 1146, in f1_score\n","    return fbeta_score(\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py\", line 1287, in fbeta_score\n","    _, _, f, _ = precision_recall_fscore_support(\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py\", line 1573, in precision_recall_fscore_support\n","    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py\", line 1391, in _check_set_wise_labels\n","    raise ValueError(\n","ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n","\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n","    scores = scorer(estimator, X_test, y_test)\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n","    return self._score(\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_scorer.py\", line 282, in _score\n","    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py\", line 1146, in f1_score\n","    return fbeta_score(\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py\", line 1287, in fbeta_score\n","    _, _, f, _ = precision_recall_fscore_support(\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py\", line 1573, in precision_recall_fscore_support\n","    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py\", line 1391, in _check_set_wise_labels\n","    raise ValueError(\n","ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n","\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n","    scores = scorer(estimator, X_test, y_test)\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n","    return self._score(\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_scorer.py\", line 282, in _score\n","    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py\", line 1146, in f1_score\n","    return fbeta_score(\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py\", line 1287, in fbeta_score\n","    _, _, f, _ = precision_recall_fscore_support(\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py\", line 1573, in precision_recall_fscore_support\n","    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py\", line 1391, in _check_set_wise_labels\n","    raise ValueError(\n","ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n","\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n","    scores = scorer(estimator, X_test, y_test)\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n","    return self._score(\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_scorer.py\", line 282, in _score\n","    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py\", line 1146, in f1_score\n","    return fbeta_score(\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py\", line 1287, in fbeta_score\n","    _, _, f, _ = precision_recall_fscore_support(\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py\", line 1573, in precision_recall_fscore_support\n","    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py\", line 1391, in _check_set_wise_labels\n","    raise ValueError(\n","ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n","\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n","    scores = scorer(estimator, X_test, y_test)\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n","    return self._score(\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_scorer.py\", line 282, in _score\n","    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py\", line 1146, in f1_score\n","    return fbeta_score(\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py\", line 1287, in fbeta_score\n","    _, _, f, _ = precision_recall_fscore_support(\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py\", line 1573, in precision_recall_fscore_support\n","    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py\", line 1391, in _check_set_wise_labels\n","    raise ValueError(\n","ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n","\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n","    scores = scorer(estimator, X_test, y_test)\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n","    return self._score(\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_scorer.py\", line 282, in _score\n","    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py\", line 1146, in f1_score\n","    return fbeta_score(\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py\", line 1287, in fbeta_score\n","    _, _, f, _ = precision_recall_fscore_support(\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py\", line 1573, in precision_recall_fscore_support\n","    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py\", line 1391, in _check_set_wise_labels\n","    raise ValueError(\n","ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n","\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n","    scores = scorer(estimator, X_test, y_test)\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n","    return self._score(\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_scorer.py\", line 282, in _score\n","    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py\", line 1146, in f1_score\n","    return fbeta_score(\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py\", line 1287, in fbeta_score\n","    _, _, f, _ = precision_recall_fscore_support(\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py\", line 1573, in precision_recall_fscore_support\n","    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py\", line 1391, in _check_set_wise_labels\n","    raise ValueError(\n","ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n","\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n","    scores = scorer(estimator, X_test, y_test)\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n","    return self._score(\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_scorer.py\", line 282, in _score\n","    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py\", line 1146, in f1_score\n","    return fbeta_score(\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py\", line 1287, in fbeta_score\n","    _, _, f, _ = precision_recall_fscore_support(\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py\", line 1573, in precision_recall_fscore_support\n","    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py\", line 1391, in _check_set_wise_labels\n","    raise ValueError(\n","ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n","\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n","    scores = scorer(estimator, X_test, y_test)\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n","    return self._score(\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_scorer.py\", line 282, in _score\n","    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py\", line 1146, in f1_score\n","    return fbeta_score(\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py\", line 1287, in fbeta_score\n","    _, _, f, _ = precision_recall_fscore_support(\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py\", line 1573, in precision_recall_fscore_support\n","    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py\", line 1391, in _check_set_wise_labels\n","    raise ValueError(\n","ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n","\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n","    scores = scorer(estimator, X_test, y_test)\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n","    return self._score(\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_scorer.py\", line 282, in _score\n","    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py\", line 1146, in f1_score\n","    return fbeta_score(\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py\", line 1287, in fbeta_score\n","    _, _, f, _ = precision_recall_fscore_support(\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py\", line 1573, in precision_recall_fscore_support\n","    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py\", line 1391, in _check_set_wise_labels\n","    raise ValueError(\n","ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n","\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n","    scores = scorer(estimator, X_test, y_test)\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n","    return self._score(\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_scorer.py\", line 282, in _score\n","    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py\", line 1146, in f1_score\n","    return fbeta_score(\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py\", line 1287, in fbeta_score\n","    _, _, f, _ = precision_recall_fscore_support(\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py\", line 1573, in precision_recall_fscore_support\n","    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n","  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py\", line 1391, in _check_set_wise_labels\n","    raise ValueError(\n","ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n","\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan]\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["F1-score: 0.2513492536678681\n"]}]},{"cell_type":"code","source":["print(grid_search.best_score_)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SFzEMdo6oo1W","executionInfo":{"status":"ok","timestamp":1680759670226,"user_tz":-540,"elapsed":12,"user":{"displayName":"라크샤사","userId":"01838305003834813418"}},"outputId":"916e127b-de07-459b-8f31-912e6ebc81dc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0.7332042058660764\n"]}]},{"cell_type":"code","source":["# 모델 객체 생성\n","rfc = RandomForestClassifier()\n","\n","# 목적 함수 설정\n","def objective_function(n_estimators, max_depth):\n","    # 하이퍼파라미터 값 설정\n","    rfc.set_params(n_estimators=int(n_estimators), max_depth=int(max_depth))\n","\n","    # 모델 학습 및 예측\n","    rfc.fit(X_tfidf_train, y_train)\n","    y_pred = rfc.predict(X_tfidf_val)\n","\n","    # F1-score 계산\n","    score = f1_score(y_val, y_pred, average='macro')\n","\n","    # 목적 함수 값 반환\n","    return score\n","\n","# 범위 설정\n","pbounds = {\n","    'n_estimators': (50, 150),\n","    'max_depth': (3, 7)\n","}\n","\n","# Bayesian Optimization 수행\n","optimizer = BayesianOptimization(\n","    f=objective_function,\n","    pbounds=pbounds,\n","    random_state=42,\n",")\n","\n","optimizer.maximize(init_points=5, n_iter=10)\n","\n","# 최적의 하이퍼파라미터 값 출력\n","print(optimizer.max)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tr0aCRpa88ri","executionInfo":{"status":"ok","timestamp":1680759675809,"user_tz":-540,"elapsed":5594,"user":{"displayName":"라크샤사","userId":"01838305003834813418"}},"outputId":"502fa829-32d3-4dc9-b062-2afb9450132e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["|   iter    |  target   | max_depth | n_esti... |\n","-------------------------------------------------\n","| \u001b[0m1        \u001b[0m | \u001b[0m0.1189   \u001b[0m | \u001b[0m4.498    \u001b[0m | \u001b[0m145.1    \u001b[0m |\n","| \u001b[0m2        \u001b[0m | \u001b[0m0.1189   \u001b[0m | \u001b[0m5.928    \u001b[0m | \u001b[0m109.9    \u001b[0m |\n","| \u001b[0m3        \u001b[0m | \u001b[0m0.1189   \u001b[0m | \u001b[0m3.624    \u001b[0m | \u001b[0m65.6     \u001b[0m |\n","| \u001b[0m4        \u001b[0m | \u001b[0m0.1189   \u001b[0m | \u001b[0m3.232    \u001b[0m | \u001b[0m136.6    \u001b[0m |\n","| \u001b[0m5        \u001b[0m | \u001b[0m0.1189   \u001b[0m | \u001b[0m5.404    \u001b[0m | \u001b[0m120.8    \u001b[0m |\n","| \u001b[95m6        \u001b[0m | \u001b[95m0.1212   \u001b[0m | \u001b[95m6.062    \u001b[0m | \u001b[95m50.0     \u001b[0m |\n","| \u001b[0m7        \u001b[0m | \u001b[0m0.1189   \u001b[0m | \u001b[0m5.343    \u001b[0m | \u001b[0m50.31    \u001b[0m |\n","| \u001b[0m8        \u001b[0m | \u001b[0m0.1189   \u001b[0m | \u001b[0m3.405    \u001b[0m | \u001b[0m102.2    \u001b[0m |\n","| \u001b[0m9        \u001b[0m | \u001b[0m0.1189   \u001b[0m | \u001b[0m3.023    \u001b[0m | \u001b[0m96.38    \u001b[0m |\n","| \u001b[0m10       \u001b[0m | \u001b[0m0.1189   \u001b[0m | \u001b[0m5.67     \u001b[0m | \u001b[0m114.2    \u001b[0m |\n","| \u001b[0m11       \u001b[0m | \u001b[0m0.1189   \u001b[0m | \u001b[0m3.13     \u001b[0m | \u001b[0m71.52    \u001b[0m |\n","| \u001b[0m12       \u001b[0m | \u001b[0m0.1189   \u001b[0m | \u001b[0m4.767    \u001b[0m | \u001b[0m132.4    \u001b[0m |\n","| \u001b[0m13       \u001b[0m | \u001b[0m0.1189   \u001b[0m | \u001b[0m3.074    \u001b[0m | \u001b[0m93.83    \u001b[0m |\n","| \u001b[0m14       \u001b[0m | \u001b[0m0.1189   \u001b[0m | \u001b[0m4.581    \u001b[0m | \u001b[0m98.74    \u001b[0m |\n","| \u001b[0m15       \u001b[0m | \u001b[0m0.1189   \u001b[0m | \u001b[0m5.761    \u001b[0m | \u001b[0m62.24    \u001b[0m |\n","=================================================\n","{'target': 0.12119035575788231, 'params': {'max_depth': 6.062187002063443, 'n_estimators': 50.001163475536615}}\n"]}]},{"cell_type":"markdown","metadata":{"id":"fkAyKK1wtb21"},"source":["## 4. Deep Learning(Sequence)\n","* Sequence로 전처리한 데이터를 이용하여 DNN, 1-D CNN, LSTM 등 3가지 이상의 deep learning 모델 학습 및 성능 분석\n","> * [Google Tutorial](https://developers.google.com/machine-learning/guides/text-classification)\n","> * [Tensorflow Tutorial](https://www.tensorflow.org/tutorials/keras/text_classification)\n","> * [Keras-tutorial](https://keras.io/examples/nlp/text_classification_from_scratch/)"]},{"cell_type":"markdown","metadata":{"id":"zRCuuMiBtb22"},"source":["### 4-1. DNN"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Q8ZxY7hztb22"},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.backend import clear_session\n","from tensorflow.keras.layers import Dense, Embedding, Flatten, Conv1D, LSTM, Dropout\n","from tensorflow.keras.models import Sequential, Model"]},{"cell_type":"code","source":["# X_mor_sequence_train = [str(x) for x in X_mor_sequence_train]\n","tokenizer = Tokenizer(lower=False)\n","tokenizer.fit_on_texts(X_mor_sequence_train)\n","\n","X_train_seq = tokenizer.texts_to_sequences(X_mor_sequence_train)\n","X_val_seq = tokenizer.texts_to_sequences(X_mor_sequence_val.tolist())\n","X_test_seq = tokenizer.texts_to_sequences(X_mor_sequence_te)"],"metadata":{"id":"3r9GSD2NAIlk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"b1ZcRrvrARvR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ls5kOgzctb22"},"source":["### 4-2. 1-D CNN"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IiJug_Uetb22"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"Hs1G0NpKtb22"},"source":["### 4-3. LSTM"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JP2ORh74tb22"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"KAF8ShDrtb22"},"source":["## 5. Using pre-trained model(Optional)\n","* 한국어 pre-trained model로 fine tuning 및 성능 분석\n","> * [BERT-tutorial](https://www.tensorflow.org/text/guide/bert_preprocessing_guide)\n","> * [HuggingFace-Korean](https://huggingface.co/models?language=korean)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HrUSc5Kmtb22"},"outputs":[],"source":["!pip install transformers\n","!pip install torch"]},{"cell_type":"code","source":["import pandas as pd\n","from transformers import BertTokenizer\n","\n","tokenizer = BertTokenizer.from_pretrained(\"bert-base-multilingual-cased\", do_lower_case=False)\n","result = tokenizer.tokenize('안녕하세요')\n","print(result)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hVnBZFMyPIrQ","executionInfo":{"status":"ok","timestamp":1680762265907,"user_tz":-540,"elapsed":680,"user":{"displayName":"라크샤사","userId":"01838305003834813418"}},"outputId":"bc8f3279-9056-4e4e-bdca-6f13d94b64bf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/eff018e45de5364a8368df1f2df3461d506e2a111e9dd50af1fae061cd460ead.fc4c9d144e9e0cd8cfa0ba00f258c8f9355e6cfa7352a7650ef401642bc1a486\n","loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/added_tokens.json from cache at None\n","loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/special_tokens_map.json from cache at None\n","loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/f55e7a2ad4f8d0fff2733b3f79777e1e99247f2e4583703e92ce74453af8c235.ec5c189f89475aac7d8cbd243960a0655cfadc3d0474da8ff2ed0bf1699c2a5f\n","loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/46880f3b0081fda494a4e15b05787692aa4c1e21e0ff2428ba8b14d4eda0784d.83291874684d6eb4d7cb8db2759eed3d758e36f96133d1de94a6a57da1504995\n"]},{"output_type":"stream","name":"stdout","text":["['안', '##녕', '##하', '##세', '##요']\n"]}]},{"cell_type":"code","source":["tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased', do_lower_case=False)\n","tokenized_texts = [tokenizer.tokenize(s) for s in X_tfidf_train]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":452},"id":"tOt3_eJEPPpc","executionInfo":{"status":"error","timestamp":1680762335228,"user_tz":-540,"elapsed":664,"user":{"displayName":"라크샤사","userId":"01838305003834813418"}},"outputId":"503b8b55-bc01-4f91-e59c-f922a6c362c5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/eff018e45de5364a8368df1f2df3461d506e2a111e9dd50af1fae061cd460ead.fc4c9d144e9e0cd8cfa0ba00f258c8f9355e6cfa7352a7650ef401642bc1a486\n","loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/added_tokens.json from cache at None\n","loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/special_tokens_map.json from cache at None\n","loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/f55e7a2ad4f8d0fff2733b3f79777e1e99247f2e4583703e92ce74453af8c235.ec5c189f89475aac7d8cbd243960a0655cfadc3d0474da8ff2ed0bf1699c2a5f\n","loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/46880f3b0081fda494a4e15b05787692aa4c1e21e0ff2428ba8b14d4eda0784d.83291874684d6eb4d7cb8db2759eed3d758e36f96133d1de94a6a57da1504995\n"]},{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-36-72041ce2b85b>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBertTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bert-base-multilingual-cased'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdo_lower_case\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtokenized_texts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX_tfidf_train\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-36-72041ce2b85b>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBertTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bert-base-multilingual-cased'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdo_lower_case\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtokenized_texts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX_tfidf_train\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils.py\u001b[0m in \u001b[0;36mtokenize\u001b[0;34m(self, text, **kwargs)\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0mno_split_token\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique_no_split_tokens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m         \u001b[0mtokenized_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit_on_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mno_split_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtokenized_text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils.py\u001b[0m in \u001b[0;36msplit_on_tokens\u001b[0;34m(tok_list, text)\u001b[0m\n\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0msplit_on_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtok_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    337\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtok_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/scipy/sparse/_base.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    769\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetnnz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 771\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattr\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" not found\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    772\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: strip not found"]}]},{"cell_type":"code","source":[],"metadata":{"id":"m0eO5xN0PerV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments, DataCollatorWithPadding\n","from torch.utils.data import Dataset, DataLoader\n","\n","# tokenizer와 pretrained model 불러오기\n","tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n","model = BertForSequenceClassification.from_pretrained('bert-base-multilingual-cased')\n","\n","# dataset 불러오기\n","# train_dataset = CustomDataset(X_tfidf_train, y_train)\n","# eval_dataset = CustomDataset(X_tfidf_val, y_val)\n","train_dataset = (X_tfidf_train, y_train, X_tfidf_train.shape[0])\n","eval_dataset = (X_tfidf_val, y_val, X_tfidf_val.shape[0])\n","\n","# TrainingArguments 설정\n","training_args = TrainingArguments(\n","    output_dir='./results',\n","    num_train_epochs=3,\n","    per_device_train_batch_size=8,\n","    per_device_eval_batch_size=64,\n","    gradient_accumulation_steps = 2,\n","    warmup_steps=500,\n","    weight_decay=0.01,\n","    logging_dir='./logs',\n","    logging_steps=100,\n","    evaluation_strategy='steps',\n","    eval_steps=500,\n","    load_best_model_at_end=True\n",")\n","\n","data_collator = DataCollatorWithPadding(tokenizer=tokenizer, padding=True, max_length=512)\n","# Trainer 객체 생성\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_dataset,\n","    eval_dataset=eval_dataset,\n","    data_collator = data_collator\n",")\n","\n","# fine tuning 진행\n","trainer.train()\n","\n","# 평가\n","trainer.evaluate()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"rDC3f5NkpHSv","executionInfo":{"status":"error","timestamp":1680760091379,"user_tz":-540,"elapsed":4253,"user":{"displayName":"라크샤사","userId":"01838305003834813418"}},"outputId":"19faff45-4d4e-408e-eb98-4e9bc46a190e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/eff018e45de5364a8368df1f2df3461d506e2a111e9dd50af1fae061cd460ead.fc4c9d144e9e0cd8cfa0ba00f258c8f9355e6cfa7352a7650ef401642bc1a486\n","loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/added_tokens.json from cache at None\n","loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/special_tokens_map.json from cache at None\n","loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/f55e7a2ad4f8d0fff2733b3f79777e1e99247f2e4583703e92ce74453af8c235.ec5c189f89475aac7d8cbd243960a0655cfadc3d0474da8ff2ed0bf1699c2a5f\n","loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/46880f3b0081fda494a4e15b05787692aa4c1e21e0ff2428ba8b14d4eda0784d.83291874684d6eb4d7cb8db2759eed3d758e36f96133d1de94a6a57da1504995\n","loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c\n","Model config BertConfig {\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"directionality\": \"bidi\",\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"pooler_fc_size\": 768,\n","  \"pooler_num_attention_heads\": 12,\n","  \"pooler_num_fc_layers\": 3,\n","  \"pooler_size_per_head\": 128,\n","  \"pooler_type\": \"first_token_transform\",\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.8.1\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 119547\n","}\n","\n","loading weights file https://huggingface.co/bert-base-multilingual-cased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/0a3fd51713dcbb4def175c7f85bddc995d5976ce1dde327f99104e4d33069f17.aa7be4c79d76f4066d9b354496ea477c9ee39c5d889156dd1efb680643c2b052\n","Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n","***** Running training *****\n","  Num examples = 3\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 2\n","  Total optimization steps = 3\n","/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:2619: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n","  if self.model_input_names[0] not in encoded_inputs:\n"]},{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-34-2b4fcf0540bc>\u001b[0m in \u001b[0;36m<cell line: 52>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;31m# fine tuning 진행\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;31m# 평가\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, **kwargs)\u001b[0m\n\u001b[1;32m   1241\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1243\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1245\u001b[0m                 \u001b[0;31m# Skip past any already trained steps if resuming training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/data/data_collator.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, features)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         batch = self.tokenizer.pad(\n\u001b[0m\u001b[1;32m    119\u001b[0m             \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mpad\u001b[0;34m(self, encoded_inputs, padding, max_length, pad_to_multiple_of, return_attention_mask, return_tensors, verbose)\u001b[0m\n\u001b[1;32m   2617\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2618\u001b[0m         \u001b[0;31m# The model's main input name, usually `input_ids`, has be passed for padding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2619\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_input_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mencoded_inputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2620\u001b[0m             raise ValueError(\n\u001b[1;32m   2621\u001b[0m                 \u001b[0;34m\"You should supply an encoding or a list of encodings to this method \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/scipy/sparse/_compressed.py\u001b[0m in \u001b[0;36m__eq__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;31m# Scalar other.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misscalarlike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbool_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: ufunc 'isnan' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''"]}]},{"cell_type":"code","source":["!pip install --upgrade kobert"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nGQO4Hh5-M5x","executionInfo":{"status":"ok","timestamp":1680757856722,"user_tz":-540,"elapsed":43201,"user":{"displayName":"라크샤사","userId":"01838305003834813418"}},"outputId":"3f0799a7-51d1-4f50-d339-321687ad24d3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: kobert in /usr/local/lib/python3.9/dist-packages (0.2.3)\n","Requirement already satisfied: boto3<=1.15.18 in /usr/local/lib/python3.9/dist-packages (from kobert) (1.15.18)\n","Requirement already satisfied: mxnet<=1.7.0.post2,>=1.4.0 in /usr/local/lib/python3.9/dist-packages (from kobert) (1.7.0.post2)\n","Collecting torch<=1.10.1,>=1.7.0\n","  Using cached torch-1.10.1-cp39-cp39-manylinux1_x86_64.whl (881.9 MB)\n","Requirement already satisfied: onnxruntime<=1.8.0,==1.8.0 in /usr/local/lib/python3.9/dist-packages (from kobert) (1.8.0)\n","Collecting transformers<=4.8.1,>=4.8.1\n","  Using cached transformers-4.8.1-py3-none-any.whl (2.5 MB)\n","Requirement already satisfied: gluonnlp<=0.10.0,>=0.6.0 in /usr/local/lib/python3.9/dist-packages (from kobert) (0.10.0)\n","Requirement already satisfied: sentencepiece<=0.1.96,>=0.1.6 in /usr/local/lib/python3.9/dist-packages (from kobert) (0.1.96)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.9/dist-packages (from onnxruntime<=1.8.0,==1.8.0->kobert) (3.20.3)\n","Requirement already satisfied: flatbuffers in /usr/local/lib/python3.9/dist-packages (from onnxruntime<=1.8.0,==1.8.0->kobert) (23.3.3)\n","Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.9/dist-packages (from onnxruntime<=1.8.0,==1.8.0->kobert) (1.22.4)\n","Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.9/dist-packages (from boto3<=1.15.18->kobert) (0.10.0)\n","Requirement already satisfied: botocore<1.19.0,>=1.18.18 in /usr/local/lib/python3.9/dist-packages (from boto3<=1.15.18->kobert) (1.18.18)\n","Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.9/dist-packages (from boto3<=1.15.18->kobert) (0.3.7)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from gluonnlp<=0.10.0,>=0.6.0->kobert) (23.0)\n","Requirement already satisfied: cython in /usr/local/lib/python3.9/dist-packages (from gluonnlp<=0.10.0,>=0.6.0->kobert) (0.29.34)\n","Requirement already satisfied: graphviz<0.9.0,>=0.8.1 in /usr/local/lib/python3.9/dist-packages (from mxnet<=1.7.0.post2,>=1.4.0->kobert) (0.8.4)\n","Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.9/dist-packages (from mxnet<=1.7.0.post2,>=1.4.0->kobert) (2.27.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch<=1.10.1,>=1.7.0->kobert) (4.5.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers<=4.8.1,>=4.8.1->kobert) (2022.10.31)\n","Collecting tokenizers<0.11,>=0.10.1\n","  Using cached tokenizers-0.10.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers<=4.8.1,>=4.8.1->kobert) (3.10.7)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers<=4.8.1,>=4.8.1->kobert) (4.65.0)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.9/dist-packages (from transformers<=4.8.1,>=4.8.1->kobert) (0.0.53)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.9/dist-packages (from transformers<=4.8.1,>=4.8.1->kobert) (6.0)\n","Collecting huggingface-hub==0.0.12\n","  Using cached huggingface_hub-0.0.12-py3-none-any.whl (37 kB)\n","Requirement already satisfied: urllib3<1.26,>=1.20 in /usr/local/lib/python3.9/dist-packages (from botocore<1.19.0,>=1.18.18->boto3<=1.15.18->kobert) (1.25.11)\n","Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.9/dist-packages (from botocore<1.19.0,>=1.18.18->boto3<=1.15.18->kobert) (2.8.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.20.0->mxnet<=1.7.0.post2,>=1.4.0->kobert) (3.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.20.0->mxnet<=1.7.0.post2,>=1.4.0->kobert) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.20.0->mxnet<=1.7.0.post2,>=1.4.0->kobert) (2.0.12)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.9/dist-packages (from sacremoses->transformers<=4.8.1,>=4.8.1->kobert) (1.1.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from sacremoses->transformers<=4.8.1,>=4.8.1->kobert) (1.16.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.9/dist-packages (from sacremoses->transformers<=4.8.1,>=4.8.1->kobert) (8.1.3)\n","Installing collected packages: tokenizers, torch, huggingface-hub, transformers\n","  Attempting uninstall: tokenizers\n","    Found existing installation: tokenizers 0.13.3\n","    Uninstalling tokenizers-0.13.3:\n","      Successfully uninstalled tokenizers-0.13.3\n","  Attempting uninstall: torch\n","    Found existing installation: torch 2.0.0\n","    Uninstalling torch-2.0.0:\n","      Successfully uninstalled torch-2.0.0\n","  Attempting uninstall: huggingface-hub\n","    Found existing installation: huggingface-hub 0.13.3\n","    Uninstalling huggingface-hub-0.13.3:\n","      Successfully uninstalled huggingface-hub-0.13.3\n","  Attempting uninstall: transformers\n","    Found existing installation: transformers 4.27.4\n","    Uninstalling transformers-4.27.4:\n","      Successfully uninstalled transformers-4.27.4\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchvision 0.15.1+cu118 requires torch==2.0.0, but you have torch 1.10.1 which is incompatible.\n","torchtext 0.15.1 requires torch==2.0.0, but you have torch 1.10.1 which is incompatible.\n","torchdata 0.6.0 requires torch==2.0.0, but you have torch 1.10.1 which is incompatible.\n","torchaudio 2.0.1+cu118 requires torch==2.0.0, but you have torch 1.10.1 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed huggingface-hub-0.0.12 tokenizers-0.10.3 torch-1.10.1 transformers-4.8.1\n"]}]},{"cell_type":"code","source":["!pip install --upgrade transformers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"az1edEdRp0cn","executionInfo":{"status":"ok","timestamp":1680758104728,"user_tz":-540,"elapsed":11280,"user":{"displayName":"라크샤사","userId":"01838305003834813418"}},"outputId":"dd988440-96b8-462f-96b0-136e94e4a0dc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: transformers in /usr/local/lib/python3.9/dist-packages (4.8.1)\n","Collecting transformers\n","  Using cached transformers-4.27.4-py3-none-any.whl (6.8 MB)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n","  Using cached tokenizers-0.13.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","Collecting huggingface-hub<1.0,>=0.11.0\n","  Using cached huggingface_hub-0.13.3-py3-none-any.whl (199 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.10.7)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n","Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.27.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.0.12)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.25.11)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","  Attempting uninstall: tokenizers\n","    Found existing installation: tokenizers 0.10.3\n","    Uninstalling tokenizers-0.10.3:\n","      Successfully uninstalled tokenizers-0.10.3\n","  Attempting uninstall: huggingface-hub\n","    Found existing installation: huggingface-hub 0.0.12\n","    Uninstalling huggingface-hub-0.0.12:\n","      Successfully uninstalled huggingface-hub-0.0.12\n","  Attempting uninstall: transformers\n","    Found existing installation: transformers 4.8.1\n","    Uninstalling transformers-4.8.1:\n","      Successfully uninstalled transformers-4.8.1\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","kobert 0.2.3 requires torch<=1.10.1,>=1.7.0, but you have torch 2.0.0 which is incompatible.\n","kobert 0.2.3 requires transformers<=4.8.1,>=4.8.1, but you have transformers 4.27.4 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed huggingface-hub-0.13.3 tokenizers-0.13.3 transformers-4.27.4\n"]}]},{"cell_type":"code","source":["pip install torch==2.0.0 torchvision==0.15.1+cu118 torchtext==0.15.1 torchdata==0.6.0 torchaudio==2.0.1+cu118 -U"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Tz2Xb03n9X2W","executionInfo":{"status":"ok","timestamp":1680757988456,"user_tz":-540,"elapsed":32928,"user":{"displayName":"라크샤사","userId":"01838305003834813418"}},"outputId":"2dd0051c-b76e-441e-d018-89cc540639f0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting torch==2.0.0\n","  Using cached torch-2.0.0-cp39-cp39-manylinux1_x86_64.whl (619.9 MB)\n","Requirement already satisfied: torchvision==0.15.1+cu118 in /usr/local/lib/python3.9/dist-packages (0.15.1+cu118)\n","Requirement already satisfied: torchtext==0.15.1 in /usr/local/lib/python3.9/dist-packages (0.15.1)\n","Requirement already satisfied: torchdata==0.6.0 in /usr/local/lib/python3.9/dist-packages (0.6.0)\n","Requirement already satisfied: torchaudio==2.0.1+cu118 in /usr/local/lib/python3.9/dist-packages (2.0.1+cu118)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch==2.0.0) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch==2.0.0) (1.11.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch==2.0.0) (3.0)\n","Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.9/dist-packages (from torch==2.0.0) (8.5.0.96)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch==2.0.0) (3.10.7)\n","Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.9/dist-packages (from torch==2.0.0) (11.10.3.66)\n","Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.9/dist-packages (from torch==2.0.0) (11.4.0.1)\n","Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.9/dist-packages (from torch==2.0.0) (11.7.99)\n","Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.9/dist-packages (from torch==2.0.0) (2.14.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch==2.0.0) (3.1.2)\n","Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.9/dist-packages (from torch==2.0.0) (11.7.101)\n","Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.9/dist-packages (from torch==2.0.0) (10.2.10.91)\n","Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.9/dist-packages (from torch==2.0.0) (11.7.91)\n","Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.9/dist-packages (from torch==2.0.0) (11.7.4.91)\n","Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.9/dist-packages (from torch==2.0.0) (10.9.0.58)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch==2.0.0) (2.0.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.9/dist-packages (from torch==2.0.0) (11.7.99)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.9/dist-packages (from torchvision==0.15.1+cu118) (8.4.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from torchvision==0.15.1+cu118) (2.27.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from torchvision==0.15.1+cu118) (1.22.4)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from torchtext==0.15.1) (4.65.0)\n","Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.9/dist-packages (from torchdata==0.6.0) (1.25.11)\n","Requirement already satisfied: wheel in /usr/local/lib/python3.9/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0) (0.40.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0) (67.6.1)\n","Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch==2.0.0) (16.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch==2.0.0) (3.25.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch==2.0.0) (2.1.2)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision==0.15.1+cu118) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision==0.15.1+cu118) (3.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision==0.15.1+cu118) (2022.12.7)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch==2.0.0) (1.3.0)\n","Installing collected packages: torch\n","  Attempting uninstall: torch\n","    Found existing installation: torch 1.10.1\n","    Uninstalling torch-1.10.1:\n","      Successfully uninstalled torch-1.10.1\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","kobert 0.2.3 requires torch<=1.10.1,>=1.7.0, but you have torch 2.0.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed torch-2.0.0\n"]}]},{"cell_type":"code","source":["pip install git+https://git@github.com/SKTBrain/KoBERT.git@master"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zxVGZFKL7RXG","executionInfo":{"status":"ok","timestamp":1680757148879,"user_tz":-540,"elapsed":104378,"user":{"displayName":"라크샤사","userId":"01838305003834813418"}},"outputId":"d4092341-f0e8-48f4-c508-ed2cdd9543ee"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting git+https://****@github.com/SKTBrain/KoBERT.git@master\n","  Cloning https://****@github.com/SKTBrain/KoBERT.git (to revision master) to /tmp/pip-req-build-64wnlb9i\n","  Running command git clone --filter=blob:none --quiet 'https://****@github.com/SKTBrain/KoBERT.git' /tmp/pip-req-build-64wnlb9i\n","  Resolved https://****@github.com/SKTBrain/KoBERT.git to commit 47a69af87928fc24e20f571fe10c3cc9dd9af9a3\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting boto3<=1.15.18\n","  Downloading boto3-1.15.18-py2.py3-none-any.whl (129 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.1/129.1 KB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting gluonnlp<=0.10.0,>=0.6.0\n","  Downloading gluonnlp-0.10.0.tar.gz (344 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m344.5/344.5 KB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting mxnet<=1.7.0.post2,>=1.4.0\n","  Downloading mxnet-1.7.0.post2-py2.py3-none-manylinux2014_x86_64.whl (54.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.7/54.7 MB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting onnxruntime<=1.8.0,==1.8.0\n","  Downloading onnxruntime-1.8.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting sentencepiece<=0.1.96,>=0.1.6\n","  Downloading sentencepiece-0.1.96-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m75.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torch<=1.10.1,>=1.7.0\n","  Downloading torch-1.10.1-cp39-cp39-manylinux1_x86_64.whl (881.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m881.9/881.9 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting transformers<=4.8.1,>=4.8.1\n","  Downloading transformers-4.8.1-py3-none-any.whl (2.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m96.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: protobuf in /usr/local/lib/python3.9/dist-packages (from onnxruntime<=1.8.0,==1.8.0->kobert==0.2.3) (3.20.3)\n","Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.9/dist-packages (from onnxruntime<=1.8.0,==1.8.0->kobert==0.2.3) (1.22.4)\n","Requirement already satisfied: flatbuffers in /usr/local/lib/python3.9/dist-packages (from onnxruntime<=1.8.0,==1.8.0->kobert==0.2.3) (23.3.3)\n","Collecting jmespath<1.0.0,>=0.7.1\n","  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n","Collecting botocore<1.19.0,>=1.18.18\n","  Downloading botocore-1.18.18-py2.py3-none-any.whl (6.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.7/6.7 MB\u001b[0m \u001b[31m110.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting s3transfer<0.4.0,>=0.3.0\n","  Downloading s3transfer-0.3.7-py2.py3-none-any.whl (73 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.4/73.4 KB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: cython in /usr/local/lib/python3.9/dist-packages (from gluonnlp<=0.10.0,>=0.6.0->kobert==0.2.3) (0.29.34)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from gluonnlp<=0.10.0,>=0.6.0->kobert==0.2.3) (23.0)\n","Collecting graphviz<0.9.0,>=0.8.1\n","  Downloading graphviz-0.8.4-py2.py3-none-any.whl (16 kB)\n","Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.9/dist-packages (from mxnet<=1.7.0.post2,>=1.4.0->kobert==0.2.3) (2.27.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch<=1.10.1,>=1.7.0->kobert==0.2.3) (4.5.0)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m880.6/880.6 KB\u001b[0m \u001b[31m54.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (2022.10.31)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (4.65.0)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.9/dist-packages (from transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (6.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (3.10.7)\n","Collecting tokenizers<0.11,>=0.10.1\n","  Downloading tokenizers-0.10.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m90.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting huggingface-hub==0.0.12\n","  Downloading huggingface_hub-0.0.12-py3-none-any.whl (37 kB)\n","Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.9/dist-packages (from botocore<1.19.0,>=1.18.18->boto3<=1.15.18->kobert==0.2.3) (2.8.2)\n","Collecting urllib3<1.26,>=1.20\n","  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.0/128.0 KB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.20.0->mxnet<=1.7.0.post2,>=1.4.0->kobert==0.2.3) (3.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.20.0->mxnet<=1.7.0.post2,>=1.4.0->kobert==0.2.3) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.20.0->mxnet<=1.7.0.post2,>=1.4.0->kobert==0.2.3) (2.0.12)\n","Requirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from sacremoses->transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (1.16.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.9/dist-packages (from sacremoses->transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (8.1.3)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.9/dist-packages (from sacremoses->transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (1.1.1)\n","Building wheels for collected packages: kobert, gluonnlp, sacremoses\n","  Building wheel for kobert (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for kobert: filename=kobert-0.2.3-py3-none-any.whl size=15705 sha256=43779606366e713a4f9bf8a8355213b6aad9ecd75a7f59847cc7a5bf4e095cd6\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-wyamjvwk/wheels/0b/20/d8/031374f3d29b5150c59c814bed091fca7d6d4c8218148bf286\n","  Building wheel for gluonnlp (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gluonnlp: filename=gluonnlp-0.10.0-cp39-cp39-linux_x86_64.whl size=680537 sha256=2fb2744ed61b688b3f04d6f2c51e1dabcb1691ba7403facdb217ef1b455b9e6c\n","  Stored in directory: /root/.cache/pip/wheels/47/17/70/b257bc53879a458c4bfcc900e89271aa8b4f19366a54bd2455\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895259 sha256=9d7e5a1c6df894f1685ae52c3c5d2444fcc94dbbd59537ce4f6e09b899f4467c\n","  Stored in directory: /root/.cache/pip/wheels/12/1c/3d/46cf06718d63a32ff798a89594b61e7f345ab6b36d909ce033\n","Successfully built kobert gluonnlp sacremoses\n","Installing collected packages: tokenizers, sentencepiece, urllib3, torch, sacremoses, onnxruntime, jmespath, graphviz, gluonnlp, botocore, s3transfer, mxnet, huggingface-hub, transformers, boto3, kobert\n","  Attempting uninstall: tokenizers\n","    Found existing installation: tokenizers 0.13.3\n","    Uninstalling tokenizers-0.13.3:\n","      Successfully uninstalled tokenizers-0.13.3\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 1.26.15\n","    Uninstalling urllib3-1.26.15:\n","      Successfully uninstalled urllib3-1.26.15\n","  Attempting uninstall: torch\n","    Found existing installation: torch 2.0.0+cu118\n","    Uninstalling torch-2.0.0+cu118:\n","      Successfully uninstalled torch-2.0.0+cu118\n","  Attempting uninstall: graphviz\n","    Found existing installation: graphviz 0.20.1\n","    Uninstalling graphviz-0.20.1:\n","      Successfully uninstalled graphviz-0.20.1\n","  Attempting uninstall: huggingface-hub\n","    Found existing installation: huggingface-hub 0.13.3\n","    Uninstalling huggingface-hub-0.13.3:\n","      Successfully uninstalled huggingface-hub-0.13.3\n","  Attempting uninstall: transformers\n","    Found existing installation: transformers 4.27.4\n","    Uninstalling transformers-4.27.4:\n","      Successfully uninstalled transformers-4.27.4\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchvision 0.15.1+cu118 requires torch==2.0.0, but you have torch 1.10.1 which is incompatible.\n","torchtext 0.15.1 requires torch==2.0.0, but you have torch 1.10.1 which is incompatible.\n","torchdata 0.6.0 requires torch==2.0.0, but you have torch 1.10.1 which is incompatible.\n","torchaudio 2.0.1+cu118 requires torch==2.0.0, but you have torch 1.10.1 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed boto3-1.15.18 botocore-1.18.18 gluonnlp-0.10.0 graphviz-0.8.4 huggingface-hub-0.0.12 jmespath-0.10.0 kobert-0.2.3 mxnet-1.7.0.post2 onnxruntime-1.8.0 s3transfer-0.3.7 sacremoses-0.0.53 sentencepiece-0.1.96 tokenizers-0.10.3 torch-1.10.1 transformers-4.8.1 urllib3-1.25.11\n"]}]},{"cell_type":"code","source":["pip install torch==1.10.1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-zyX1zhT_wLs","executionInfo":{"status":"ok","timestamp":1680758250408,"user_tz":-540,"elapsed":37500,"user":{"displayName":"라크샤사","userId":"01838305003834813418"}},"outputId":"f92c1ece-2552-4d2c-922c-30f8d4f3c4e4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting torch==1.10.1\n","  Using cached torch-1.10.1-cp39-cp39-manylinux1_x86_64.whl (881.9 MB)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch==1.10.1) (4.5.0)\n","Installing collected packages: torch\n","  Attempting uninstall: torch\n","    Found existing installation: torch 2.0.0\n","    Uninstalling torch-2.0.0:\n","      Successfully uninstalled torch-2.0.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchvision 0.15.1+cu118 requires torch==2.0.0, but you have torch 1.10.1 which is incompatible.\n","torchtext 0.15.1 requires torch==2.0.0, but you have torch 1.10.1 which is incompatible.\n","torchdata 0.6.0 requires torch==2.0.0, but you have torch 1.10.1 which is incompatible.\n","torchaudio 2.0.1+cu118 requires torch==2.0.0, but you have torch 1.10.1 which is incompatible.\n","kobert 0.2.3 requires transformers<=4.8.1,>=4.8.1, but you have transformers 4.27.4 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed torch-1.10.1\n"]}]},{"cell_type":"code","source":["!pip install transformers==4.8.1\n","!pip install kobert"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"e3-UFQWvAOic","executionInfo":{"status":"ok","timestamp":1680758349910,"user_tz":-540,"elapsed":12253,"user":{"displayName":"라크샤사","userId":"01838305003834813418"}},"outputId":"3390199f-9fcf-44ee-a69e-334bb5056ca0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers==4.8.1\n","  Using cached transformers-4.8.1-py3-none-any.whl (2.5 MB)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers==4.8.1) (4.65.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from transformers==4.8.1) (23.0)\n","Collecting tokenizers<0.11,>=0.10.1\n","  Using cached tokenizers-0.10.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.9/dist-packages (from transformers==4.8.1) (6.0)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.9/dist-packages (from transformers==4.8.1) (0.0.53)\n","Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers==4.8.1) (2.27.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers==4.8.1) (3.10.7)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers==4.8.1) (1.22.4)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers==4.8.1) (2022.10.31)\n","Collecting huggingface-hub==0.0.12\n","  Using cached huggingface_hub-0.0.12-py3-none-any.whl (37 kB)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from huggingface-hub==0.0.12->transformers==4.8.1) (4.5.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers==4.8.1) (3.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers==4.8.1) (2022.12.7)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers==4.8.1) (1.25.11)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers==4.8.1) (2.0.12)\n","Requirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from sacremoses->transformers==4.8.1) (1.16.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.9/dist-packages (from sacremoses->transformers==4.8.1) (1.1.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.9/dist-packages (from sacremoses->transformers==4.8.1) (8.1.3)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","  Attempting uninstall: tokenizers\n","    Found existing installation: tokenizers 0.13.3\n","    Uninstalling tokenizers-0.13.3:\n","      Successfully uninstalled tokenizers-0.13.3\n","  Attempting uninstall: huggingface-hub\n","    Found existing installation: huggingface-hub 0.13.3\n","    Uninstalling huggingface-hub-0.13.3:\n","      Successfully uninstalled huggingface-hub-0.13.3\n","  Attempting uninstall: transformers\n","    Found existing installation: transformers 4.27.4\n","    Uninstalling transformers-4.27.4:\n","      Successfully uninstalled transformers-4.27.4\n","Successfully installed huggingface-hub-0.0.12 tokenizers-0.10.3 transformers-4.8.1\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["huggingface_hub","tokenizers","transformers"]}}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: kobert in /usr/local/lib/python3.9/dist-packages (0.2.3)\n","Requirement already satisfied: sentencepiece<=0.1.96,>=0.1.6 in /usr/local/lib/python3.9/dist-packages (from kobert) (0.1.96)\n","Requirement already satisfied: mxnet<=1.7.0.post2,>=1.4.0 in /usr/local/lib/python3.9/dist-packages (from kobert) (1.7.0.post2)\n","Requirement already satisfied: onnxruntime<=1.8.0,==1.8.0 in /usr/local/lib/python3.9/dist-packages (from kobert) (1.8.0)\n","Requirement already satisfied: transformers<=4.8.1,>=4.8.1 in /usr/local/lib/python3.9/dist-packages (from kobert) (4.8.1)\n","Requirement already satisfied: gluonnlp<=0.10.0,>=0.6.0 in /usr/local/lib/python3.9/dist-packages (from kobert) (0.10.0)\n","Requirement already satisfied: torch<=1.10.1,>=1.7.0 in /usr/local/lib/python3.9/dist-packages (from kobert) (1.10.1)\n","Requirement already satisfied: boto3<=1.15.18 in /usr/local/lib/python3.9/dist-packages (from kobert) (1.15.18)\n","Requirement already satisfied: flatbuffers in /usr/local/lib/python3.9/dist-packages (from onnxruntime<=1.8.0,==1.8.0->kobert) (23.3.3)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.9/dist-packages (from onnxruntime<=1.8.0,==1.8.0->kobert) (3.20.3)\n","Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.9/dist-packages (from onnxruntime<=1.8.0,==1.8.0->kobert) (1.22.4)\n","Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.9/dist-packages (from boto3<=1.15.18->kobert) (0.3.7)\n","Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.9/dist-packages (from boto3<=1.15.18->kobert) (0.10.0)\n","Requirement already satisfied: botocore<1.19.0,>=1.18.18 in /usr/local/lib/python3.9/dist-packages (from boto3<=1.15.18->kobert) (1.18.18)\n","Requirement already satisfied: cython in /usr/local/lib/python3.9/dist-packages (from gluonnlp<=0.10.0,>=0.6.0->kobert) (0.29.34)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from gluonnlp<=0.10.0,>=0.6.0->kobert) (23.0)\n","Requirement already satisfied: graphviz<0.9.0,>=0.8.1 in /usr/local/lib/python3.9/dist-packages (from mxnet<=1.7.0.post2,>=1.4.0->kobert) (0.8.4)\n","Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.9/dist-packages (from mxnet<=1.7.0.post2,>=1.4.0->kobert) (2.27.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch<=1.10.1,>=1.7.0->kobert) (4.5.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers<=4.8.1,>=4.8.1->kobert) (2022.10.31)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers<=4.8.1,>=4.8.1->kobert) (3.10.7)\n","Requirement already satisfied: huggingface-hub==0.0.12 in /usr/local/lib/python3.9/dist-packages (from transformers<=4.8.1,>=4.8.1->kobert) (0.0.12)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.9/dist-packages (from transformers<=4.8.1,>=4.8.1->kobert) (0.0.53)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.9/dist-packages (from transformers<=4.8.1,>=4.8.1->kobert) (6.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers<=4.8.1,>=4.8.1->kobert) (4.65.0)\n","Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.9/dist-packages (from transformers<=4.8.1,>=4.8.1->kobert) (0.10.3)\n","Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.9/dist-packages (from botocore<1.19.0,>=1.18.18->boto3<=1.15.18->kobert) (2.8.2)\n","Requirement already satisfied: urllib3<1.26,>=1.20 in /usr/local/lib/python3.9/dist-packages (from botocore<1.19.0,>=1.18.18->boto3<=1.15.18->kobert) (1.25.11)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.20.0->mxnet<=1.7.0.post2,>=1.4.0->kobert) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.20.0->mxnet<=1.7.0.post2,>=1.4.0->kobert) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.20.0->mxnet<=1.7.0.post2,>=1.4.0->kobert) (3.4)\n","Requirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from sacremoses->transformers<=4.8.1,>=4.8.1->kobert) (1.16.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.9/dist-packages (from sacremoses->transformers<=4.8.1,>=4.8.1->kobert) (1.1.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.9/dist-packages (from sacremoses->transformers<=4.8.1,>=4.8.1->kobert) (8.1.3)\n"]}]},{"cell_type":"code","source":["import torch\n","from kobert import get_pytorch_kobert_model\n","\n","model, vocab = get_pytorch_kobert_model()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Cd8mfjFw7TM5","executionInfo":{"status":"ok","timestamp":1680757500954,"user_tz":-540,"elapsed":13757,"user":{"displayName":"라크샤사","userId":"01838305003834813418"}},"outputId":"777d0118-6c51-4f5a-94db-f393a79010f0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/.cache/kobert_v1.zip[██████████████████████████████████████████████████]\n","/content/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece[██████████████████████████████████████████████████]\n"]}]},{"cell_type":"code","source":["from transformers import AutoTokenizer\n","\n","tokenizer = AutoTokenizer.from_pretrained('skt/kobert-base-v1')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":378},"id":"sw4l6r-h8rwp","executionInfo":{"status":"error","timestamp":1680758364131,"user_tz":-540,"elapsed":277,"user":{"displayName":"라크샤사","userId":"01838305003834813418"}},"outputId":"ee23614b-4404-4fb8-a778-b8e3debaf172"},"execution_count":null,"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-63-ed1db03d84bc>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'skt/kobert-base-v1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/models/auto/tokenization_auto.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *init_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   1802\u001b[0m         \u001b[0;31m# tokenizer.init_kwargs = init_kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1803\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1804\u001b[0;31m         \u001b[0;31m# If there is a complementary special token map, load it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1805\u001b[0m         \u001b[0mspecial_tokens_map_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresolved_vocab_files\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"special_tokens_map_file\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1806\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mspecial_tokens_map_file\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36m_from_pretrained\u001b[0;34m(cls, resolved_vocab_files, pretrained_model_name_or_path, init_configuration, use_auth_token, cache_dir, local_files_only, _commit_hash, *init_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   1956\u001b[0m         \u001b[0mfile_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtokenizer_config_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspecial_tokens_map_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1957\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1958\u001b[0;31m         save_files = self._save_pretrained(\n\u001b[0m\u001b[1;32m   1959\u001b[0m             \u001b[0msave_directory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msave_directory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1960\u001b[0m             \u001b[0mfile_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfile_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/models/xlnet/tokenization_xlnet_fast.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, vocab_file, tokenizer_file, do_lower_case, remove_space, keep_accents, bos_token, eos_token, unk_token, sep_token, pad_token, cls_token, mask_token, additional_special_tokens, **kwargs)\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0mmask_token\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAddedToken\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlstrip\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrstrip\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmask_token\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m         super().__init__(\n\u001b[0m\u001b[1;32m    146\u001b[0m             \u001b[0mvocab_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvocab_file\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m             \u001b[0mtokenizer_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokenizer_file\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_fast.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfast_tokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mslow_tokenizer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslow_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/convert_slow_tokenizer.py\u001b[0m in \u001b[0;36mconvert_slow_tokenizer\u001b[0;34m(transformer_tokenizer)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/convert_slow_tokenizer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 445\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mAlbertConverter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSpmConverter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    446\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m         return [\n","\u001b[0;31mAttributeError\u001b[0m: byte_fallback"]}]},{"cell_type":"code","source":[],"metadata":{"id":"rGn_z8bD9KJq"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"},"accelerator":"GPU","gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}